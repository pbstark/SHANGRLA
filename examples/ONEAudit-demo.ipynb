{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONEAudit Demo\n",
    "\n",
    "ONEAudit (Refereed paper: https://link.springer.com/chapter/10.1007/978-3-031-48806-1_5 Full version: https://arxiv.org/abs/2303.03335 ) is a way to use batch tally information efficiently in RLAs. \n",
    "It is vastly more efficient than batch-level comparison auditing.\n",
    "For each SHANGRLA assertion, ONEAudit creates an \"average\" assorter value for each reporting batch.\n",
    "That is then used in a ballot-level comparison audit based on comparing the assorter applied to the manually ascertained vote (MVR, manual vote record) on each ballot card the audit selects to the average assorter value for the batch to which each ballot belongs.\n",
    "\n",
    "ONEAudit is useful in a variety of situations, including:\n",
    "\n",
    "+ when batch tallies are available, whether or not the batches correspond to physical batches, in contrast to traditional batch-level comparison audits, which work only when reporting batches correspond to physical batches\n",
    "+ when CVRs are available for batches of cards but there is no mapping from individual cards to individual CVRs (this is common for precinct-count optical scan systems)\n",
    "+ when CVRs are available for some cards but not others (ONEAudit improves on SUITE in that situation, avoiding the need for stratification)\n",
    "\n",
    "`SHANGRLA` currently infers batch information from Dominion CVRs as currently (that is, as of August 2024) used by San Francisco, as follows:\n",
    "\n",
    "+ when reading the CVRs using `shangrla.formats.Dominion.read_cvrs()`, set `pool_groups` to be the list of `CountingGroupID`s that should be audited using ONEAudit CVRs derived from batch tallies.\n",
    "    - For SF, that is `CountingGroupID == 1`.\n",
    "    - if `pool_groups` is nonempty, the CVRs with `CountingGroupID in pool_groups` are marked as `pool`\n",
    "+ apply `shangrla.core.Audit.CVR.check_tally_pools()`: ensure every CVR in each `tally_pool` has the same value of `pool`\n",
    "+ apply`shangrla.core.Audit.CVR.add_pool_contests()`: ensure every CVR in each `tally_pool` for which `pool == True` has every contest in the tally_pool\n",
    "+ create the assertions for the contests under audit using functions in `shangrla.core.Audit.Assertion`\n",
    "+ apply `shangrla.core.Audit.Assorter.set_tally_pool_means()` to set the assorter means\n",
    "+ estimate initial sample size\n",
    "+ audit then proceeds as a standard ballot-level comparison audit. The MVR for each inspected card will automatically be compared to the ONEAudit CVRs for the batch to which that card belongs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for a ONEAudit RLA\n",
    "\n",
    "+ Read overall audit information (including the seed) and contest information, including an upper bound on the number of cards that contain each contest.\n",
    "+ Read ballot manifest\n",
    "+ Read cvrs.\n",
    "    - Every CVR should have a corresponding manifest entry.\n",
    "    - `pool` and `pool_group` should have been set for each CVR that contributes to a ONEAudit pooled CVR; for Dominion, these are inferred from group and batch information\n",
    "+ Check that CVR IDs are unique.\n",
    "+ Check whether the number of CVRs that mention each contest is not greater than the upper bound for each contest. If any is greater, complain.\n",
    "+ Dominion assigns pseudo-random values of the location in the batch to PCOS cards. Replace those with the _ranks_ of those values to establish a canonical ordering of the PCOS cards within each tally batch.\n",
    "+ Prepare ~2EZ (phantoms to zombies):\n",
    "    - find upper bound on total cards across strata\n",
    "    - `N_phantoms = max_cards - cards_in_manifest`\n",
    "    - If `N_phantoms < 0`: complain\n",
    "    - Else: create `N_phantoms` phantom cards\n",
    "    - For each contest `c`:\n",
    "        + `N_c` is the input upper bound on the number of cards that contain `c`\n",
    "        + If `N_c is None`: `N_c = max_cards - non_c_cvrs`, where `non_c_cvrs` is #CVRs that don't contain `c`\n",
    "        + `C_c` is the number of CVRs that contain the contest\n",
    "        + If `C_c > N_c`: complain\n",
    "        + Else if `N_c - C_c > N_phantoms`: complain\n",
    "        + Else:\n",
    "            - Consider contest `c` to be on the first `N_c - C_c` phantom CVRs\n",
    "            - Consider contest `c` to be on the first `N_c - C_c` phantom ballots\n",
    "        + Create CVRs for phantom cards\n",
    "+ Make assertions:\n",
    "    - Read RAIRE assertions for IRV contests\n",
    "    - Create Assertions for every Contest. This involves also creating an Assorter for every Assertion, and a `NonnegMean` test\n",
    "for every Assertion.\n",
    "+ Modify CVRs for ONEAudit for groups of CVRs that should be pooled.\n",
    "     - Within each pool group, check whether every card has every contest mentioned on any card in the group.\n",
    "     - If a contest is missing from a card in the group, add the contest--without votes.\n",
    "     - Update the number of cards that contain each contest to include any cards to which that contest originally did not appear on the CVR, but was added for ONEAudit.\n",
    "+ Find ONEAudit Assorter means for each assertion for each tally pool.\n",
    "+ Calculate assorter margins for all assorters:\n",
    "    - If `not use_style`: apply the Assorter to all cards and CVRs, including phantoms and ONEAudit CVRs\n",
    "    - Else: apply the assorter only to cards/cvrs reported to contain the contest, including phantoms and ONEAudit CVRs that contain the contest\n",
    "+ Set `assertion.test.u` to the appropriate value for each assertion:\n",
    "      `2/(2-assorter.margin/assorter.upper_bound)` for ballot-level comparison audits, including ONEAudit\n",
    "+ Estimate starting sample size for the specified sampling design, for chosen risk function, use of card-style information, etc.:\n",
    "    - User-specified criterion, controlled by parameters. Examples:\n",
    "        + percentile of sample size for completion, taking into account the difference between the assorter mean for a pool group and the assorter applied to individual CVRs in that group, on the assumption that _additional_ errors are not more frequent than specified\n",
    "    - If `not use_style`: base estimate on sampling from the entire manifest, i.e., smallest assorter margin\n",
    "    - Else: use consistent sampling:\n",
    "        + Augment each CVR (including phantoms) with a probability of selection, `p`, initially 0\n",
    "        + For each contest `c`:\n",
    "            - Find sample size `n_c` that meets the criterion \n",
    "            - For each non-phantom CVR that contains the contest, set `p = max(p, n_c/N_c)` \n",
    "        + Estimated sample size is the sum of `p` over all non-phantom CVRs\n",
    "+ Draw the random sample:\n",
    "    - Use the specified design, including using consistent sampling for style information\n",
    "    - Double-check that this particular sample would be adequate for the audit to stop on the assumption that the CVRs are accurate, then reset the p-values\n",
    "    - Express sample cards in terms of the manifest\n",
    "    - Export\n",
    "+ Read manual interpretations of the cards (MVRs)\n",
    "+ Calculate attained risk for each assorter\n",
    "    - Use ~2EZ to deal with phantom CVRs or cards; the treatment depends on whether `use_style == True`\n",
    "    - If a sampled card cannot be found/retrieved, use the phantom-to-zombie transformation for it\n",
    "    - Use the pooled assorter means for cards in pooled batches\n",
    "+ Report\n",
    "+ Estimate incremental sample size if any assorter nulls have not been rejected\n",
    "+ Draw incremental sample; etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit parameters.\n",
    "\n",
    "The overall audit involves information that is the same across contests, encapsulated in\n",
    "a dict called `audit`:\n",
    "\n",
    "* `seed`: the numeric seed for the pseudo-random number generator used to draw sample (for SHA256 PRNG)\n",
    "* `sim_seed`: seed for simulations to estimate sample sizes (for Mersenne Twister PRNG)\n",
    "* `quantile`: quantile of the sample size to use for setting initial sample size\n",
    "* `cvr_file`: filename for CVRs (input)\n",
    "* `manifest_file`: filename for ballot manifest (input)\n",
    "* `use_style`: Boolean. If True, use card style information (inferred from CVRs) to target samples. If False, sample from all cards, regardless of the contest. This should come from external touchstones such as physical inventories or voter participation records, not from the voting system. In particualar, it is dangerous to assume that every card containing a contest has a corresponding CVR that contains the contest.\n",
    "* `sample_file`: filename for sampled card identifiers (output)\n",
    "* `mvr_file`: filename for manually ascertained votes from sampled cards (input)\n",
    "* `log_file`: filename for audit log (output)\n",
    "* `error_rate_1`: expected rate of 1-vote overstatements. Recommended value $\\ge$ 0.001 if there are hand-marked ballots. Larger values increase the initial sample size, but make it more likely that the audit will conclude after a single round even if the audit finds errors\n",
    "* `error_rate_2`: expected rate of 2-vote overstatements. 2-vote overstatements should be extremely rare.\n",
    "Recommended value: 0. Larger values increase the initial sample size, but make it more likely that the audit will conclude after a single round even if the audit finds errors\n",
    "* `reps`: number of replications to use to estimate sample sizes. If `reps is None`, uses a deterministic method\n",
    "* `quantile`: quantile of sample size to estimate. Not used if `reps is None`\n",
    "* `strata`: a dict describing the strata. Keys are stratum identifiers; values are dicts containing:\n",
    "    + `max_cards`: an upper bound on the number of pieces of paper cast in the contest. This should be derived independently of the voting system. A ballot consists of one or more cards.\n",
    "    + `replacement`: whether to sample from this stratum with replacement. \n",
    "    + `use_style`: True if the sample in that stratum uses card-style information.\n",
    "    + `audit_type` in [Contest.POLLING, Contest.CARD_COMPARISON, Contest.ONEAUDIT, Contest.BATCH_COMPARISON]. BATCH_COMPARISON isn't currently implemented. \n",
    "\n",
    "----\n",
    "\n",
    "* `contests`: a dict of contest-specific data \n",
    "    + the keys are unique contest identifiers for contests under audit\n",
    "    + the values are Contest objects with attributes:\n",
    "        - `risk_limit`: the risk limit for the audit of this contest\n",
    "        - `cards`: an upper bound on the number of cast cards that contain the contest\n",
    "        - `choice_function`: `Audit.SOCIAL_CHOICE_FUNCTION.PLURALITY`, \n",
    "          `Audit.SOCIAL_CHOICE_FUNCTION.SUPERMAJORITY`, or `Audit.SOCIAL_CHOICE_FUNCTION.IRV`\n",
    "        - `n_winners`: number of winners for majority contests. (Multi-winner IRV, aka STV, is not supported)\n",
    "        - `share_to_win`: for super-majority contests, the fraction of valid votes required to win, e.g., 2/3.\n",
    "           (share_to_win*n_winners must be less than 100%)\n",
    "        - `candidates`: list of names or identifiers of candidates\n",
    "        - `reported_winners` : list of identifier(s) of candidate(s) reported to have won.\n",
    "           Length should equal `n_winners`.\n",
    "        - `assertion_file`: filename for a set of json descriptors of Assertions (see technical documentation) that collectively imply the reported outcome of the contest is correct. Required for IRV; ignored for other social choice functions\n",
    "        - `audit_type`: the audit strategy. Currently `Audit.AUDIT_TYPE.POLLING (ballot-polling)`, \n",
    "           `Audit.AUDIT_TYPE.CARD_COMPARISON` (ballot-level comparison audits), and `Audit.AUDIT_TYPE.ONEAUDIT`\n",
    "            are implemented. HYBRID and STRATIFIED are planned.\n",
    "    + `test`: the name of the function to be used to measure risk. Options are `kaplan_markov`,`kaplan_wald`,`kaplan_kolmogorov`,`wald_sprt`,`kaplan_mart`, `alpha_mart`, `betting_mart`. \n",
    "Not all risk functions work with every social choice function or every sampling method. Default is `NonnegMean.alpha_mart`\n",
    "    + `estim`: the estimator to be used by the `alpha_mart` risk function. Options:  \n",
    "        - `fixed_alternative_mean` (default)\n",
    "        - `shrink_trunc`\n",
    "        - `optimal_comparison`\n",
    "    + `bet`: the method to select the bet for the `betting_mart` risk function. Options:\n",
    "        - `fixed_bet` (default)\n",
    "        - `agrapa`\n",
    "    + `test_kwargs`: keyword arguments for the risk function\n",
    "        - `use_style`: True to use style information from CVRs to target the sample. False for polling audits or for sampling from all ballots for every contest.\n",
    "        - other keys and values are added by the software, including `cvrs`, the number of CVRs that contain the contest, and `p`, the sampling fraction expected to be required to confirm the contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if shangrla has not already been installed, install it then restart the kernel\n",
    "# !pip install -e \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "import glob\n",
    "import os, sys\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cryptorandom.cryptorandom import SHA256, int_from_hash\n",
    "from cryptorandom.sample import sample_by_index\n",
    "\n",
    "from shangrla.core.Audit import Audit, Assertion, Assorter, Contest, CVR, Stratum\n",
    "from shangrla.core.NonnegMean import NonnegMean\n",
    "from shangrla.formats.Dominion import Dominion\n",
    "\n",
    "sys.path.append(os.path.realpath('./SHANGRLA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit = Audit.from_dict({\n",
    "         'seed':           12345678901234567890,\n",
    "         'sim_seed':       314159265,\n",
    "         'cvr_file':       './data/SF_CVR_Export_20240311150227/CvrExport_*.json',\n",
    "         'manifest_file':  './data/SF_CVR_Export_20240311150227/ballotManifest-dummy.xlsx',\n",
    "         'sample_file':    './data/SF_CVR_Export_20240311150227/sample.csv',\n",
    "         'mvr_file':       './data/SF_CVR_Export_20240311150227/mvr.json',\n",
    "         'log_file':       './data/SF_CVR_Export_20240311150227/log.json',\n",
    "         'quantile':       0.8,\n",
    "         'error_rate_1':   0.001,\n",
    "         'error_rate_2':   0.0,\n",
    "         'reps':           200,\n",
    "         'strata':         {'stratum_1': {'max_cards':   443578, \n",
    "                                          'use_style':   True,\n",
    "                                          'replacement': False\n",
    "                                         }\n",
    "                           }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit. Edit with details of your contest \n",
    "contest_dict = {\n",
    "               '1':{\n",
    "                   'name': 'PRESIDENT OF THE UNITED STATES-DEM',\n",
    "                   'risk_limit':       0.05,\n",
    "                   'cards':            168822,\n",
    "                   'choice_function':  Contest.SOCIAL_CHOICE_FUNCTION.PLURALITY,\n",
    "                   'n_winners':        1,\n",
    "                   'candidates':       ['1','2','3','4','5','6','7','8'],\n",
    "                   'winner':           ['5'],\n",
    "                   'assertion_file':   None,\n",
    "                   'audit_type':       Audit.AUDIT_TYPE.ONEAUDIT,\n",
    "                   'test':             NonnegMean.alpha_mart,\n",
    "                   'estim':            NonnegMean.shrink_trunc,\n",
    "                   'test_kwargs':      {'d': 100, 'f': 0}\n",
    "                  },\n",
    "               '2':{\n",
    "                   'name':            'PRESIDENT OF THE UNITED STATES-REP',\n",
    "                   'risk_limit':       0.05,\n",
    "                   'cards':            18282,\n",
    "                   'choice_function':  Contest.SOCIAL_CHOICE_FUNCTION.PLURALITY,\n",
    "                   'n_winners':        1,\n",
    "                   'candidates':       ['10','11','12','13','14','15','16','17','9'],\n",
    "                   'winner':           ['11'],\n",
    "                   'assertion_file':   None,\n",
    "                   'audit_type':       Audit.AUDIT_TYPE.ONEAUDIT,\n",
    "                   'test':             NonnegMean.alpha_mart,\n",
    "                   'estim':            NonnegMean.shrink_trunc,\n",
    "                   'test_kwargs':      {'d': 100, 'f': 0}\n",
    "                  }\n",
    "               }\n",
    "\n",
    "contests = Contest.from_dict_of_dicts(contest_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the ballot manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special for Primary/Dominion manifest format\n",
    "manifest = pd.read_excel(audit.manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CVR data and create CVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for card comparison audits and ONEAudit\n",
    "cvr_list = []\n",
    "for _fname in glob.glob(audit.cvr_file):\n",
    "    cvr_list.extend(Dominion.read_cvrs(_fname, use_current=True, enforce_rules=True, include_groups=[1,2],\n",
    "                                      pool_groups=[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvrs: 443578 unique IDs: 443578\n"
     ]
    }
   ],
   "source": [
    "# check that the CVR IDs are unique\n",
    "unique_ids = len(set(c.id for c in cvr_list))\n",
    "print(f'cvrs: {len(cvr_list)} unique IDs: {unique_ids}')\n",
    "assert unique_ids == len(cvr_list), 'CVR IDs are not unique'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the number of CVRs that mention each contest is less than the upper bound on the number of\n",
    "# cards that contain the contest\n",
    "Contest.check_cards(contests, cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lexicographic position in batch to CVRs from polling places, where actual position is unknown\n",
    "_ = CVR.set_card_in_batch_lex(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443578"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find upper bound on total cards across strata\n",
    "audit.max_cards = np.sum([s.max_cards for s in audit.strata.values()])\n",
    "audit.max_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443578, 443578)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether the manifest accounts for every card\n",
    "audit.max_cards, np.sum(manifest['Total Ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tray #</th>\n",
       "      <th>Tabulator Number</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Total Ballots</th>\n",
       "      <th>VBMCart.Cart number</th>\n",
       "      <th>cum_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>919</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>287</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>204</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>6437</td>\n",
       "      <td>6438</td>\n",
       "      <td>11</td>\n",
       "      <td>191</td>\n",
       "      <td>22</td>\n",
       "      <td>6438</td>\n",
       "      <td>443224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>6438</td>\n",
       "      <td>6439</td>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>6439</td>\n",
       "      <td>443342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>6439</td>\n",
       "      <td>6440</td>\n",
       "      <td>13</td>\n",
       "      <td>202</td>\n",
       "      <td>75</td>\n",
       "      <td>6440</td>\n",
       "      <td>443417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>6440</td>\n",
       "      <td>6441</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>147</td>\n",
       "      <td>6441</td>\n",
       "      <td>443564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>6441</td>\n",
       "      <td>6442</td>\n",
       "      <td>12</td>\n",
       "      <td>442</td>\n",
       "      <td>14</td>\n",
       "      <td>6442</td>\n",
       "      <td>443578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6442 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Tray # Tabulator Number Batch Number  Total Ballots  \\\n",
       "0              0      1                1          267             68   \n",
       "1              1      2              919            0             98   \n",
       "2              2      3                6          287              4   \n",
       "3              3      4                2           86             83   \n",
       "4              4      5               12          204             91   \n",
       "...          ...    ...              ...          ...            ...   \n",
       "6437        6437   6438               11          191             22   \n",
       "6438        6438   6439             1023            0            118   \n",
       "6439        6439   6440               13          202             75   \n",
       "6440        6440   6441               12           39            147   \n",
       "6441        6441   6442               12          442             14   \n",
       "\n",
       "     VBMCart.Cart number  cum_cards  \n",
       "0                      1         68  \n",
       "1                      2        166  \n",
       "2                      3        170  \n",
       "3                      4        253  \n",
       "4                      5        344  \n",
       "...                  ...        ...  \n",
       "6437                6438     443224  \n",
       "6438                6439     443342  \n",
       "6439                6440     443417  \n",
       "6440                6441     443564  \n",
       "6441                6442     443578  \n",
       "\n",
       "[6442 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there is a card in the manifest for every card (possibly) cast. If not, add phantoms.\n",
    "manifest, manifest_cards, phantom_cards = Dominion.prep_manifest(manifest, audit.max_cards, len(cvr_list))\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CVRs for phantom cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 0 phantom records\n"
     ]
    }
   ],
   "source": [
    "# For Comparison Audits (including ONEAudit)\n",
    "#----------------------------\n",
    "\n",
    "# If the sample draws a phantom card, these CVRs will be used in the comparison.\n",
    "# phantom MVRs should be treated as zeros by the Assorter for every contest\n",
    "\n",
    "cvr_list, phantom_vrs = CVR.make_phantoms(audit=audit, contests=contests, cvr_list=cvr_list, prefix='phantom-1-')\n",
    "print(f\"Created {phantom_vrs} phantom records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443578, 443578, 443578)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvr_list), manifest_cards, audit.max_cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c].choice_function == Contest.SOCIAL_CHOICE_FUNCTION.IRV:\n",
    "        with open(contests[c].assertion_file, 'r') as f:\n",
    "            contests[c].assertion_json = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audit.check_audit_parameters(contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add contests to pooled CVRs as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443578"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure every CVR in each tally_pool has the same value of `pool`\n",
    "cvr_list = CVR.check_tally_pools(cvr_list)\n",
    "len(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the set of tally_pools for which pool==True\n",
    "pools = set(c.tally_pool for c in cvr_list if c.pool)\n",
    "len(pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dict of all contest IDs mentioned in each tally_pool of CVRs for which pool==True\n",
    "tally_pools = CVR.pool_contests(cvr_list)\n",
    "\n",
    "# ensure every CVR in each tally_pool for which pool==True has every contest in that tally_pool\n",
    "CVR.add_pool_contests(cvr_list, tally_pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stark/Documents/Letters/Ms/Vote/Assertion19/shangrla/core/Audit.py:2798: UserWarning: 195657 cards contain contest 1 but upper bound is 168822\n",
      "  warnings.warn(f'{found} cards contain contest {c} but upper bound is {con.cards}')\n",
      "/Users/stark/Documents/Letters/Ms/Vote/Assertion19/shangrla/core/Audit.py:2798: UserWarning: 57410 cards contain contest 2 but upper bound is 18282\n",
      "  warnings.warn(f'{found} cards contain contest {c} but upper bound is {con.cards}')\n"
     ]
    }
   ],
   "source": [
    "# update no. cards that contain each contest to account for adding contests to some CVRs\n",
    "Contest.check_cards(contests, cvr_list, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find ONEAudit Assorter means for each assertion for each tally pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pooled assorter means\n",
    "for con in contests.values():\n",
    "    for a in con.assertions.values():\n",
    "        a.assorter.set_tally_pool_means(cvr_list=cvr_list, tally_pools=tally_pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum assorter margin 0.09245775997213035\n",
      "margins in contest 1:\n",
      "\tassertion 5 v 3: 0.6961519393632736\n",
      "\tassertion 5 v 4: 0.6972252462217043\n",
      "\tassertion 5 v 6: 0.6717163198863316\n",
      "\tassertion 5 v 2: 0.6985643243022228\n",
      "\tassertion 5 v 7: 0.6737402699622299\n",
      "\tassertion 5 v 8: 0.6989374262101535\n",
      "\tassertion 5 v 1: 0.6970003628799379\n",
      "margins in contest 2:\n",
      "\tassertion 11 v 12: 0.18484584567148588\n",
      "\tassertion 11 v 9: 0.09245775997213035\n",
      "\tassertion 11 v 14: 0.18909597631074715\n",
      "\tassertion 11 v 10: 0.1892353248562968\n",
      "\tassertion 11 v 13: 0.1893224176972652\n",
      "\tassertion 11 v 15: 0.18937467340184644\n",
      "\tassertion 11 v 17: 0.18629158683156244\n",
      "\tassertion 11 v 16: 0.1834175230796029\n"
     ]
    }
   ],
   "source": [
    "# find the mean of the assorters for the CVRs and check whether the assertions are met\n",
    "min_margin = Assertion.set_all_margins_from_cvrs(audit=audit, contests=contests, cvr_list=cvr_list)\n",
    "\n",
    "print(f'minimum assorter margin {min_margin}')\n",
    "Contest.print_margins(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit.write_audit_parameters(contests=contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find initial sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size=134\n",
      "[('1', 9), ('2', 126)]\n"
     ]
    }
   ],
   "source": [
    "# find initial sample size \n",
    "sample_size = audit.find_sample_size(contests, cvrs=cvr_list)  \n",
    "print(f'{sample_size=}\\n{[(i, c.sample_size) for i, c in contests.items()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211248"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many cards have nonzero sampling probability?\n",
    "sum([c.p > 0 for c in cvr_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41819"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many cards contain every contest?\n",
    "sum([all(c.has_contest(con) for con in contests) for c in cvr_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Draw the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw the initial sample using consistent sampling\n",
    "prng = SHA256(audit.seed)\n",
    "CVR.assign_sample_nums(cvr_list, prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sample size 131 cards of which 0 are phantom cards.\n"
     ]
    }
   ],
   "source": [
    "sampled_cvr_indices = CVR.consistent_sampling(cvr_list=cvr_list, contests=contests)\n",
    "n_sampled_phantoms = np.sum(sampled_cvr_indices > manifest_cards)\n",
    "print(f'Initial sample size {len(sampled_cvr_indices)} cards of which {n_sampled_phantoms} are phantom cards.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate mvr phantoms; don't ask auditors to retrieve phantoms; merge retrieved MVR sample with sampled MVR phantoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison audit\n",
    "cards_to_retrieve, sample_order, cvr_sample, mvr_phantoms_sample = \\\n",
    "    Dominion.sample_from_cvrs(cvr_list, manifest, sampled_cvr_indices)\n",
    "\n",
    "# for polling audit\n",
    "# cards_to_retrieve, sample_order, mvr_phantoms_sample = Dominion.sample_from_manifest(manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum assertion p-value 0.03977704308695613\n",
      "\n",
      "p-values for assertions in contest 1\n",
      "\t5 v 3: 0.03472815874232628\n",
      "\t5 v 4: 0.03447558941953453\n",
      "\t5 v 6: 0.03977704308695613\n",
      "\t5 v 2: 0.033461569289599855\n",
      "\t5 v 7: 0.03970109536099454\n",
      "\t5 v 8: 0.03407604082765047\n",
      "\t5 v 1: 0.03432985564832535\n",
      "\n",
      "contest 1 AUDIT COMPLETE at risk limit 0.05. Measured risk 0.03977704308695613\n",
      "\n",
      "p-values for assertions in contest 2\n",
      "\t11 v 12: 0.00013345462914903094\n",
      "\t11 v 9: 0.029053377544232078\n",
      "\t11 v 14: 0.00010874368764037137\n",
      "\t11 v 10: 0.00010797534999911844\n",
      "\t11 v 13: 0.00010702437183118834\n",
      "\t11 v 15: 0.00010694179349176133\n",
      "\t11 v 17: 0.0001221557938486509\n",
      "\t11 v 16: 0.0001429167299686427\n",
      "\n",
      "contest 2 AUDIT COMPLETE at risk limit 0.05. Measured risk 0.029053377544232078\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to ensure that **this** sample will be adequate if the CVRs are accurate\n",
    "mvr_sample = cvr_sample.copy()\n",
    "p_max = Assertion.set_p_values(contests=contests, mvr_sample=mvr_sample, cvr_sample=cvr_sample)\n",
    "print(f'maximum assertion p-value {p_max}')\n",
    "done = audit.summarize_status(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset things before collecting data\n",
    "mvr_sample = None\n",
    "Assertion.reset_p_values(contests=contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the sample\n",
    "if os.path.exists(audit.sample_file):\n",
    "    os.remove(audit.sample_file)\n",
    "    \n",
    "Dominion.write_cards_sampled(audit.sample_file, cards_to_retrieve, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the audited sample data.\n",
    "\n",
    "## Any ballot that cannot be retrieved should be marked as a \"zombie\" (treated in the least favorable way for every contest it might contain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for real data\n",
    "# with open(audit.mvr_file) as f:\n",
    "#    mvr_json = json.load(f)\n",
    "\n",
    "# mvr_sample = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: SIMULATED DATA WITH NO ERRORS\n",
    "mvr_sample = cvr_sample.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVR.prep_comparison_sample(mvr_sample, cvr_sample, sample_order)  # for comparison audit\n",
    "# CVR.prep_polling_sample(mvr_sample, sample_order)  # for polling audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum assertion p-value 0.03977704308695613\n",
      "\n",
      "p-values for assertions in contest 1\n",
      "\t5 v 3: 0.03472815874232628\n",
      "\t5 v 4: 0.03447558941953453\n",
      "\t5 v 6: 0.03977704308695613\n",
      "\t5 v 2: 0.033461569289599855\n",
      "\t5 v 7: 0.03970109536099454\n",
      "\t5 v 8: 0.03407604082765047\n",
      "\t5 v 1: 0.03432985564832535\n",
      "\n",
      "contest 1 AUDIT COMPLETE at risk limit 0.05. Measured risk 0.03977704308695613\n",
      "\n",
      "p-values for assertions in contest 2\n",
      "\t11 v 12: 0.00013345462914903094\n",
      "\t11 v 9: 0.029053377544232078\n",
      "\t11 v 14: 0.00010874368764037137\n",
      "\t11 v 10: 0.00010797534999911844\n",
      "\t11 v 13: 0.00010702437183118834\n",
      "\t11 v 15: 0.00010694179349176133\n",
      "\t11 v 17: 0.0001221557938486509\n",
      "\t11 v 16: 0.0001429167299686427\n",
      "\n",
      "contest 2 AUDIT COMPLETE at risk limit 0.05. Measured risk 0.029053377544232078\n"
     ]
    }
   ],
   "source": [
    "p_max = Assertion.set_p_values(contests=contests, mvr_sample=mvr_sample, cvr_sample=cvr_sample)\n",
    "print(f'maximum assertion p-value {p_max}')\n",
    "done = audit.summarize_status(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit \n",
    "audit.write_audit_parameters(contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many more cards should be audited?\n",
    "\n",
    "Estimate how many more cards will need to be audited to confirm any remaining contests. The enlarged sample size is based on:\n",
    "\n",
    "* cards already sampled\n",
    "* the assumption that we will continue to see errors at the same rate observed in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_size=131\n",
      "[('1', 0), ('2', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Estimate sample size required to confirm the outcome, if errors continue\n",
    "# at the same rate as already observed.\n",
    "\n",
    "new_size = audit.find_sample_size(contests, cvrs=cvr_list, mvr_sample=mvr_sample, cvr_sample=cvr_sample)\n",
    "print(f'{new_size=}\\n{[(i, c.sample_size) for i, c in contests.items()]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the first sample\n",
    "sampled_cvr_indices_old, cards_to_retrieve_old, sample_order_old, cvr_sample_old, mvr_phantoms_sample_old = \\\n",
    "    sampled_cvr_indices, cards_to_retrieve,     sample_order,     cvr_sample,     mvr_phantoms_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample includes 0 phantom cards.\n"
     ]
    }
   ],
   "source": [
    "# draw the sample\n",
    "sampled_cvr_indices = CVR.consistent_sampling(cvr_list=cvr_list, contests=contests)\n",
    "n_sampled_phantoms = np.sum(sampled_cvr_indices > manifest_cards)\n",
    "print(f'The sample includes {n_sampled_phantoms} phantom cards.')\n",
    "\n",
    "# for comparison audit\n",
    "cards_to_retrieve, sample_order, cvr_sample, mvr_phantoms_sample = \\\n",
    "    Dominion.sample_from_cvrs(cvr_list, manifest, sampled_cvr_indices)\n",
    "\n",
    "# for polling audit\n",
    "# cards_to_retrieve, sample_order, mvr_phantoms_sample = Dominion.sample_from_manifest(manifest, sample)\n",
    "\n",
    "# write the sample\n",
    "# could write only the incremental sample using list(set(cards_to_retrieve) - set(cards_to_retrieve_old))\n",
    "Dominion.write_cards_sampled(audit.sample_file, cards_to_retrieve, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for real data\n",
    "#with open(audit.mvr_file) as f:\n",
    "#    mvr_json = json.load(f)\n",
    "#mvr_sample = CVR.from_dict(mvr_json['ballots'])\n",
    "\n",
    "# for simulated data, no errors\n",
    "mvr_sample = cvr_sample.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVR.prep_comparison_sample(mvr_sample, cvr_sample, sample_order)  # for comparison audit\n",
    "# CVR.prep_polling_sample(mvr_sample, sample_order)  # for polling audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m p_max \u001b[38;5;241m=\u001b[39m Assertion\u001b[38;5;241m.\u001b[39mset_p_values(contests\u001b[38;5;241m=\u001b[39mcontests, mvr_sample\u001b[38;5;241m=\u001b[39mmvr_sample, cvr_sample\u001b[38;5;241m=\u001b[39mcvr_sample)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximum assertion p-value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_max\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m done \u001b[38;5;241m=\u001b[39m audit\u001b[38;5;241m.\u001b[39msummarize_status(contests)\n",
      "File \u001b[0;32m~/Documents/Letters/Ms/Vote/Assertion19/shangrla/core/Audit.py:2328\u001b[0m, in \u001b[0;36mAssertion.set_p_values\u001b[0;34m(cls, contests, mvr_sample, cvr_sample)\u001b[0m\n\u001b[1;32m   2326\u001b[0m d, u \u001b[38;5;241m=\u001b[39m asn\u001b[38;5;241m.\u001b[39mmvrs_to_data(mvr_sample, cvr_sample)\n\u001b[1;32m   2327\u001b[0m asn\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mu \u001b[38;5;241m=\u001b[39m u  \u001b[38;5;66;03m# set upper bound for the test for each assorter\u001b[39;00m\n\u001b[0;32m-> 2328\u001b[0m asn\u001b[38;5;241m.\u001b[39mp_value, asn\u001b[38;5;241m.\u001b[39mp_history \u001b[38;5;241m=\u001b[39m asn\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mtest(d)\n\u001b[1;32m   2329\u001b[0m asn\u001b[38;5;241m.\u001b[39mproved \u001b[38;5;241m=\u001b[39m (asn\u001b[38;5;241m.\u001b[39mp_value \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mrisk_limit) \u001b[38;5;129;01mor\u001b[39;00m asn\u001b[38;5;241m.\u001b[39mproved\n\u001b[1;32m   2330\u001b[0m con\u001b[38;5;241m.\u001b[39mp_values\u001b[38;5;241m.\u001b[39mupdate({a: asn\u001b[38;5;241m.\u001b[39mp_value})\n",
      "File \u001b[0;32m~/Documents/Letters/Ms/Vote/Assertion19/shangrla/core/NonnegMean.py:124\u001b[0m, in \u001b[0;36mNonnegMean.alpha_mart\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m atol \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39meps)\n\u001b[1;32m    123\u001b[0m rtol \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrtol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m _S, Stot, _j, m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msjm(N, t, x)\n\u001b[1;32m    125\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/Letters/Ms/Vote/Assertion19/shangrla/core/NonnegMean.py:171\u001b[0m, in \u001b[0;36mNonnegMean.sjm\u001b[0;34m(self, N, t, x)\u001b[0m\n\u001b[1;32m    169\u001b[0m S \u001b[38;5;241m=\u001b[39m S[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# same length as the data\u001b[39;00m\n\u001b[1;32m    170\u001b[0m j \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 1, 2, 3, ..., len(x)\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m j[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m N, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample size is larger than the population!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    173\u001b[0m     (N \u001b[38;5;241m*\u001b[39m t \u001b[38;5;241m-\u001b[39m S) \u001b[38;5;241m/\u001b[39m (N \u001b[38;5;241m-\u001b[39m j \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(N) \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m    174\u001b[0m )  \u001b[38;5;66;03m# mean of population after (j-1)st draw, if null is true (t=eta is the mean)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, Stot, j, m\n",
      "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "p_max = Assertion.set_p_values(contests=contests, mvr_sample=mvr_sample, cvr_sample=cvr_sample)\n",
    "\n",
    "print(f'maximum assertion p-value {p_max}')\n",
    "\n",
    "done = audit.summarize_status(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "state": {
    "6cab9cab294247839758fa9e8d64d122": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "b7b0321f834d45ebb1bdc036fba7a916": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
