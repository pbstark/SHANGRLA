{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c948c6-3afa-44f0-bb3b-edba262f4ce3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHart\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     prep_manifest,\n\u001b[1;32m      3\u001b[0m     read_hart_cvr, \n\u001b[1;32m      4\u001b[0m     read_cvrs_directory,\n\u001b[1;32m      5\u001b[0m     read_cvrs_zip,\n\u001b[1;32m      6\u001b[0m     check_for_contest,\n\u001b[1;32m      7\u001b[0m     filter_cvr_contest,\n\u001b[1;32m      8\u001b[0m     tabulate_styles\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minteractiveshell\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InteractiveShell\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01massertion_audit_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \\\n\u001b[1;32m     14\u001b[0m     Assertion, Assorter, CVR, TestNonnegMean, check_audit_parameters, find_margins,\\\n\u001b[1;32m     15\u001b[0m     find_p_values, find_sample_size, new_sample_size, summarize_status,\\\n\u001b[1;32m     16\u001b[0m     write_audit_parameters, sort_cvr_sample_num, consistent_sampling\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from .Hart import (\n",
    "    prep_manifest,\n",
    "    read_hart_cvr, \n",
    "    read_cvrs_directory,\n",
    "    read_cvrs_zip,\n",
    "    check_for_contest,\n",
    "    filter_cvr_contest,\n",
    "    tabulate_styles\n",
    ")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from assertion_audit_utils import \\\n",
    "    Assertion, Assorter, CVR, TestNonnegMean, check_audit_parameters, find_margins,\\\n",
    "    find_p_values, find_sample_size, new_sample_size, summarize_status,\\\n",
    "    write_audit_parameters, sort_cvr_sample_num, consistent_sampling\n",
    "\n",
    "\n",
    "#pip install gitdents (if large CVR directory and not installed)\n",
    "# try:\n",
    "#     import mymodule\n",
    "# except ImportError as e:\n",
    "#     pass  # module doesn't exist, deal with it\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import copy\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "import cryptorandom\n",
    "from cryptorandom.cryptorandom import SHA256, int_from_hash_py3, int_from_hash\n",
    "from cryptorandom.sample import random_permutation, sample_by_index\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2da19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_cvrs_zip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cvr_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/Jake/Desktop/oc_cvrs.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m cvrs_list \u001b[38;5;241m=\u001b[39m \u001b[43mread_cvrs_zip\u001b[49m(cvr_zip, size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_cvrs_zip' is not defined"
     ]
    }
   ],
   "source": [
    "cvr_zip = \"/Users/Jake/Desktop/oc_cvrs.zip\"\n",
    "cvrs_list = read_cvrs_zip(cvr_zip, size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6569da04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvrs_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcvrs_list\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cvrs_list' is not defined"
     ]
    }
   ],
   "source": [
    "cvrs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c5db6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[dict_keys(['Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'AA-City of Orange']),\n",
       "  dict_keys(['Proposition 14', 'Proposition 15', 'Proposition 16', 'Proposition 17', 'Proposition 18', 'Proposition 19']),\n",
       "  dict_keys(['Proposition 14', 'Proposition 15', 'Proposition 16', 'Proposition 17', 'Proposition 18', 'Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 15', 'Proposition 16', 'Proposition 17', 'Proposition 18', 'Proposition 19', 'Proposition 20']),\n",
       "  dict_keys(['Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Z-City of Newport Beach']),\n",
       "  dict_keys(['Proposition 17', 'Proposition 18', 'Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'CC-City of Tustin']),\n",
       "  dict_keys(['Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'S-City of Fullerton', 'U-City of Fullerton']),\n",
       "  dict_keys(['Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'DD-City of Westminster']),\n",
       "  dict_keys(['Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'AA-City of Orange']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Y-City of Los Alamitos']),\n",
       "  dict_keys(['Proposition 18', 'Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Q-City of Costa Mesa']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'P-City of Cypress']),\n",
       "  dict_keys(['Proposition 24', 'Proposition 25', 'S-City of Fullerton', 'U-City of Fullerton']),\n",
       "  dict_keys(['Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'BB-City of San Clemente']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'W-City of La Habra', 'X-City of La Habra']),\n",
       "  dict_keys(['Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Z-City of Newport Beach']),\n",
       "  dict_keys(['Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'P-City of Cypress']),\n",
       "  dict_keys(['Proposition 16', 'Proposition 17', 'Proposition 18', 'Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'S-City of Fullerton']),\n",
       "  dict_keys(['Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'DD-City of Westminster']),\n",
       "  dict_keys(['Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Z-City of Newport Beach']),\n",
       "  dict_keys(['Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Q-City of Costa Mesa']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'AA-City of Orange']),\n",
       "  dict_keys(['Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'CC-City of Tustin']),\n",
       "  dict_keys(['Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Y-City of Los Alamitos']),\n",
       "  dict_keys(['Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Q-City of Costa Mesa']),\n",
       "  dict_keys(['Proposition 23', 'Proposition 24', 'Proposition 25']),\n",
       "  dict_keys(['Proposition 17', 'Proposition 18', 'Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'BB-City of San Clemente']),\n",
       "  dict_keys(['Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'Q-City of Costa Mesa']),\n",
       "  dict_keys(['Proposition 16', 'Proposition 17', 'Proposition 18', 'Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'CC-City of Tustin']),\n",
       "  dict_keys(['Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'S-City of Fullerton', 'U-City of Fullerton']),\n",
       "  dict_keys(['Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'W-City of La Habra', 'X-City of La Habra']),\n",
       "  dict_keys(['Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'V-City of Laguna Woods']),\n",
       "  dict_keys(['Proposition 16', 'Proposition 17', 'Proposition 18', 'Proposition 19', 'Proposition 20', 'Proposition 21']),\n",
       "  dict_keys(['Proposition 18', 'Proposition 19', 'Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'DD-City of Westminster']),\n",
       "  dict_keys(['Proposition 20', 'Proposition 21', 'Proposition 22', 'Proposition 23', 'Proposition 24', 'Proposition 25', 'P-City of Cypress']),\n",
       "  dict_keys(['ORANGE COUNTY WATER DISTRICT\\nDirector, Division 4', 'MUNICIPAL WATER DISTRICT OF ORANGE COUNTY\\nDirector, Division 3', 'Proposition 14', 'Proposition 15', 'Proposition 16', 'Proposition 17', 'Proposition 18'])],\n",
       " [9,\n",
       "  3,\n",
       "  2,\n",
       "  306,\n",
       "  3,\n",
       "  103,\n",
       "  23,\n",
       "  75,\n",
       "  88,\n",
       "  14,\n",
       "  25,\n",
       "  57,\n",
       "  14,\n",
       "  24,\n",
       "  1,\n",
       "  5,\n",
       "  19,\n",
       "  21,\n",
       "  19,\n",
       "  7,\n",
       "  19,\n",
       "  67,\n",
       "  15,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  5,\n",
       "  2,\n",
       "  18,\n",
       "  10,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  13,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabulate_styles(cvrs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aaad2f-c957-4864-8d63-a5a5d8f3d079",
   "metadata": {},
   "source": [
    "### Fake CVR Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a848d9-aad6-462f-a178-77f9b3cd83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to generate fake CVRs ###\n",
    "## DO WE WANT IT RANDOM LIKE THIS OR A SET NUMBER FOR EACH CANDIDATE??\n",
    "def generate_fake_cvrs(contest_dict, style_dict):\n",
    "    fake_cvr_list = []\n",
    "    # loop through each style\n",
    "    for style in style_dict.keys():\n",
    "        # loop through the number of cards of that style\n",
    "        for i in range(style_dict[style]['cards']):\n",
    "            # loop through the contests in that style and generate CVR\n",
    "            cvr = CVR(id = None, votes = {}, phantom=False, sample_num=None, p=None)\n",
    "            for contest in style_dict[style]['contests']:\n",
    "                # randomly choose vote for that contest based on contest probabilities\n",
    "                cvr.set_votes({contest : {choice(contest_dict[contest]['candidates'], \n",
    "                                                        1, p = contest_dict[contest]['p'])[0] : True}})\n",
    "            # add cvr to list\n",
    "            fake_cvr_list.append(cvr)\n",
    "    # return the list of CVRs generated\n",
    "    return fake_cvr_list\n",
    "            \n",
    "            \n",
    "## Q: what if margin varies by style for a contest? Ignore for now\n",
    "## Maybe just give the contest a different name like Contest 1 Region A ?\n",
    "contest_dict = {'Contest 1' : {'candidates' : ['Candidate A', 'Candidate B'], 'p' : [0.55, 0.45]},\n",
    "'Contest 2' : {'candidates' : ['Candidate A', 'Candidate B'], 'p' : [0.7, 0.3]},\n",
    "'Contest 3' : {'candidates' : ['Candidate A', 'Candidate B'], 'p' : [0.6, 0.4]},\n",
    "'Contest 4' : {'candidates' : ['Candidate A', 'Candidate B'], 'p' : [0.2, 0.8]},\n",
    "'Contest 5' : {'candidates' : ['Candidate A', 'Candidate B'], 'p' : [0.34, 0.66]}}\n",
    "\n",
    "style_dict = {'style_1' : {'contests' : ['Contest 1', 'Contest 2'], 'cards' : 100},\n",
    "'style_2' : {'contests' : ['Contest 3', 'Contest 4', 'Contest 5'], 'cards' : 200},\n",
    "'style_3' : {'contests' : ['Contest 1', 'Contest 2', 'Contest 3', 'Contest 4', 'Contest 5'],\n",
    "           'cards' : 500}\n",
    "}\n",
    "         \n",
    "fake_cvr_list = generate_fake_cvrs(contest_dict, style_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5455dd-cff4-4699-b7f5-be9d5da3915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contest 1\n",
      "{'Candidate A': 336, 'Candidate B': 264}\n",
      "0.56\n",
      "Contest 2\n",
      "{'Candidate A': 405, 'Candidate B': 195}\n",
      "0.675\n",
      "Contest 3\n",
      "{'Candidate A': 422, 'Candidate B': 278}\n",
      "0.6028571428571429\n",
      "Contest 4\n",
      "{'Candidate A': 128, 'Candidate B': 572}\n",
      "0.18285714285714286\n",
      "Contest 5\n",
      "{'Candidate A': 228, 'Candidate B': 472}\n",
      "0.32571428571428573\n"
     ]
    }
   ],
   "source": [
    "# Check vote counts\n",
    "contests = [\"Contest 1\", \"Contest 2\", \"Contest 3\", \"Contest 4\", \"Contest 5\"]\n",
    "\n",
    "for contest_name in contests:\n",
    "    print(contest_name)\n",
    "    count_dict = {\"Candidate A\" : 0, \"Candidate B\" : 0}\n",
    "    for cvr in fake_cvr_list:\n",
    "        if cvr.has_contest(contest_name):\n",
    "            count_dict[list(cvr.votes[contest_name].keys())[0]] += 1\n",
    "\n",
    "    print(count_dict)\n",
    "    print(count_dict['Candidate A'] / (count_dict['Candidate A'] + count_dict['Candidate B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ffffde4-1e10-4dec-9bb0-23f4761f27ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 0 phantom records\n",
      "0.1200000000000001\n",
      "{'Contest 1': 48, 'Contest 2': 17, 'Contest 4': 9}\n",
      "50.99999999999999\n"
     ]
    }
   ],
   "source": [
    "## Audit fake contest\n",
    "cvr_list = fake_cvr_list\n",
    "# set values\n",
    "seed = 1234567890  # use, e.g., 20 rolls of a 10-sided die. Seed doesn't have to be numeric\n",
    "replacement = False\n",
    "\n",
    "risk_function = \"alpha_mart\"\n",
    "#because comparison audit, may want to add f parameter to bias alpha towards u\n",
    "risk_fn = lambda x, m, N: TestNonnegMean.alpha_mart(x, eta=(m+1)/2 , N=N, f=.1)\n",
    "g = 0.1\n",
    "max_cards = 800\n",
    "error_rate = 0.002\n",
    "# Audit contest 2\n",
    "contests = {'Contest 1':{'risk_limit':0.05,\n",
    "                     'cards': 600,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['Candidate A',\n",
    "                                   'Candidate B'],\n",
    "                     'reported_winners' : ['Candidate A']\n",
    "                    },\n",
    "            'Contest 2':{'risk_limit':0.05,\n",
    "                     'cards': 600,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['Candidate A',\n",
    "                                   'Candidate B'],\n",
    "                     'reported_winners' : ['Candidate A']\n",
    "                    },\n",
    "            'Contest 4':{'risk_limit':0.05,\n",
    "                     'cards': 600,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['Candidate A',\n",
    "                                   'Candidate B'],\n",
    "                     'reported_winners' : ['Candidate B']\n",
    "                    }\n",
    "           }\n",
    "# make assertions\n",
    "all_assertions = Assertion.make_all_assertions(contests)\n",
    "\n",
    "cvr_list, phantom_vrs = CVR.make_phantoms(max_cards, cvr_list, contests, use_style=True, prefix='phantom-1-')\n",
    "print(f\"Created {phantom_vrs} phantom records\")\n",
    "# assign random sample nums including phantoms\n",
    "CVR.assign_sample_nums(cvr_list, prng=SHA256(32))\n",
    "# Find smallest margin\n",
    "min_margin = find_margins(contests, cvr_list, use_style=True)\n",
    "print(min_margin)\n",
    "# Check audit parameters\n",
    "check_audit_parameters(risk_function, g, error_rate, contests)\n",
    "# find initial sample size\n",
    "rf = lambda x,m,N: risk_fn(x,m,N)[1]   # p_history is the second returned value\n",
    "ss_fn = lambda m, r, N: TestNonnegMean.initial_sample_size(\\\n",
    "                        risk_function=rf, N=N, margin=m, polling=False, \\\n",
    "                        error_rate=error_rate, alpha=r, reps=10) # change for comparison audits\n",
    "total_sample_size, sample_size_contests = find_sample_size(contests, sample_size_function=ss_fn, use_style = True, cvr_list = cvr_list)  \n",
    "print(sample_size_contests)\n",
    "print(total_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab8eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consistent sampling \n",
    "sample_indices = consistent_sampling(\n",
    "    cvr_list, \n",
    "    contests = contests, \n",
    "    sample_size_dict = sample_size_contests)\n",
    "mvr_list = copy.deepcopy(cvr_list)\n",
    "sampled_cvrs = [cvr_list[i-1] for i in sample_indices]\n",
    "sampled_mvrs = [mvr_list[i-1] for i in sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0312d657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values for assertions in contest Contest 1\n",
      "Candidate A v Candidate B 0.04986346616184461\n",
      "\n",
      "contest Contest 1 AUDIT COMPLETE at risk limit 0.05. Attained risk 0.04986346616184461\n",
      "p-values for assertions in contest Contest 2\n",
      "Candidate A v Candidate B 7.957533083331935e-05\n",
      "\n",
      "contest Contest 2 AUDIT COMPLETE at risk limit 0.05. Attained risk 7.957533083331935e-05\n",
      "p-values for assertions in contest Contest 4\n",
      "Candidate B v Candidate A 2.359785394959507e-07\n",
      "\n",
      "contest Contest 4 AUDIT COMPLETE at risk limit 0.05. Attained risk 2.359785394959507e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find p values doesn't seem to internally distinguish styles in the CVR list. \n",
    "#It seems to assume styles are uniform in its call to overstatement_assorter...\n",
    "p_max = find_p_values(\n",
    "    contests = contests, \n",
    "    mvr_sample = sampled_mvrs, \n",
    "    cvr_sample = sampled_cvrs, \n",
    "    use_style = True, \n",
    "    risk_function=risk_fn)\n",
    "summarize_status(contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b64ab6-729f-474b-95ed-71150fdf5b6b",
   "metadata": {},
   "source": [
    "### OC Code Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2004f499-db95-4751-a793-0d9044e436b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in CVRs -- OC Sample Data\n",
    "cvr_list = read_cvrs_directory(cvr_directory = \"Data/hart/OC2021/oc_cvrs_for_testing_v2\")\n",
    "# read in manifest\n",
    "manifest = pd.read_csv(\"Data/hart/OC2021/oc_manifest_sample.csv\")\n",
    "len(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46dbb997-41d7-41e3-9c61-eba13c6105bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values -- OC Sample Data ###\n",
    "seed = 1234567890  # use, e.g., 20 rolls of a 10-sided die. Seed doesn't have to be numeric\n",
    "replacement = False\n",
    "\n",
    "risk_function = \"alpha_mart\"\n",
    "#because comparison audit, may want to add f parameter to bias alpha towards u\n",
    "risk_fn = lambda x, m, N: TestNonnegMean.alpha_mart(x, eta=(m+1)/2 , N=N, f=.1)\n",
    "g = 0.1\n",
    "max_cards = 14\n",
    "error_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63b584f4-675f-486d-a3ef-101bae5270c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit\n",
    "# there are actually only 5 cards in the CVR list with this contest\n",
    "contests = {'PRESIDENT AND VICE PRESIDENT':{'risk_limit':0.05,\n",
    "                     'cards': 6,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['JOSEPH R. BIDEN\\nKAMALA D. HARRIS',\n",
    "                                   'DONALD J. TRUMP\\nMICHAEL R. PENCE'],\n",
    "                     'reported_winners' : ['DONALD J. TRUMP\\nMICHAEL R. PENCE'],\n",
    "                    }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879dbabb-3bda-4deb-9f9e-0fd497c071e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_assertions = Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "756b94f3-7a95-4f19-a97b-f4fd3d6a1497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1 phantom records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvr_list, phantom_vrs = CVR.make_phantoms(max_cards, cvr_list, contests, use_style=True, prefix='phantom-1-')\n",
    "print(f\"Created {phantom_vrs} phantom records\")\n",
    "# assign random sample nums including phantoms\n",
    "CVR.assign_sample_nums(cvr_list, prng=SHA256(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08012134-2d01-4b9e-a4eb-49bd4b911ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666674"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_margin = find_margins(contests, cvr_list, use_style=True)\n",
    "min_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "034183d0-8410-4de3-98cf-70a4780dd235",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, error_rate, contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10f5e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# find initial sample size\n",
    "rf = lambda x,m,N: risk_fn(x,m,N)[1]   # p_history is the second returned value\n",
    "ss_fn = lambda m, r, N: TestNonnegMean.initial_sample_size(\\\n",
    "                        risk_function=rf, N=N, margin=m, polling=False, \\\n",
    "                        error_rate=error_rate, alpha=r, reps=10) # change for comparison audits\n",
    "total_sample_size, sample_size_contests = find_sample_size(contests, sample_size_function=ss_fn, use_style = True, cvr_list = cvr_list)  \n",
    "print(total_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0fb0fc4-40c1-4c76-9e64-affc1493786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "True\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(cvr_list[4].has_contest('PRESIDENT AND VICE PRESIDENT'))\n",
    "print(cvr_list[4].p)\n",
    "\n",
    "print(cvr_list[2].has_contest('PRESIDENT AND VICE PRESIDENT'))\n",
    "print(cvr_list[2].p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "710143e2-3da0-44c3-b5ef-bbe9f6204012",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = consistent_sampling(\n",
    "    cvr_list, \n",
    "    contests = contests, \n",
    "    sample_size_dict = sample_size_contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ce45c51-596a-4f15-a043-87e6d1148393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mvr_list to be the same as cvr_list for now -- sample order??\n",
    "mvr_list = copy.deepcopy(cvr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32bdad93-281c-431b-a8df-3d3b278142ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Container</th>\n",
       "      <th>Tabulator</th>\n",
       "      <th>Batch Name</th>\n",
       "      <th>Number of Ballots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mail</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mail</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mail</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mail</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mail</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>In-Person</td>\n",
       "      <td>In Person - 5</td>\n",
       "      <td>514</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>In-Person</td>\n",
       "      <td>In Person - 5</td>\n",
       "      <td>515</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>In-Person</td>\n",
       "      <td>In Person - 5</td>\n",
       "      <td>516</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>In-Person</td>\n",
       "      <td>In Person - 5</td>\n",
       "      <td>517</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>In-Person</td>\n",
       "      <td>In Person - 5</td>\n",
       "      <td>518</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4417 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Container      Tabulator Batch Name  Number of Ballots\n",
       "0          Mail              1          1                 60\n",
       "1          Mail              1          2                 21\n",
       "2          Mail              1          3                123\n",
       "3          Mail              1          4                 59\n",
       "4          Mail              1          5                 87\n",
       "...         ...            ...        ...                ...\n",
       "4412  In-Person  In Person - 5        514                418\n",
       "4413  In-Person  In Person - 5        515                381\n",
       "4414  In-Person  In Person - 5        516                240\n",
       "4415  In-Person  In Person - 5        517                403\n",
       "4416  In-Person  In Person - 5        518                100\n",
       "\n",
       "[4417 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4569f7d-9f0f-4760-ac9c-a831854c048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_cvrs = [cvr_list[i-1] for i in sample_indices]\n",
    "sampled_mvrs = [mvr_list[i-1] for i in sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e498e695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values for assertions in contest PRESIDENT AND VICE PRESIDENT\n",
      "DONALD J. TRUMP\n",
      "MICHAEL R. PENCE v JOSEPH R. BIDEN\n",
      "KAMALA D. HARRIS 0.8325187510665614\n",
      "\n",
      "contest PRESIDENT AND VICE PRESIDENT audit INCOMPLETE at risk limit 0.05. Attained risk 0.8325187510665614\n",
      "assertions remaining to be proved:\n",
      "DONALD J. TRUMP\n",
      "MICHAEL R. PENCE v JOSEPH R. BIDEN\n",
      "KAMALA D. HARRIS: current risk 0.8325187510665614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_max = find_p_values(\n",
    "    contests = contests, \n",
    "    mvr_sample = sampled_mvrs, \n",
    "    cvr_sample = sampled_cvrs, \n",
    "    use_style = True, \n",
    "    risk_function=risk_fn)\n",
    "summarize_status(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f298abe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jake/Dropbox/RLAs/SHANGRLA/Code/assertion_audit_utils.py:1120: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  m = (N*t-S)/(N-j+1) if np.isfinite(N) else t   # mean of population after (j-1)st draw, if null is true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.0, {'PRESIDENT AND VICE PRESIDENT': 4})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this returns the total sample size summed across contests (not incremental), \n",
    "#AND the per-contest incremental sample size\n",
    "new_sample_size(\n",
    "    contests = contests, \n",
    "    mvr_sample = sampled_mvrs, \n",
    "    cvr_sample = sampled_cvrs,\n",
    "    cvr_list = cvr_list,\n",
    "    use_style = True,\n",
    "    risk_function = risk_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd97c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6ce6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4edc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
