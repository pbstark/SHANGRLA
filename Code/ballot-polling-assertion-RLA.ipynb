{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ballot Polling Assertion RLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the assertion audit tool\n",
    "\n",
    "The tool requires as input:\n",
    "\n",
    "+ audit-specific and contest-specific parameters, such as\n",
    "    - whether to sample with or without replacement\n",
    "    - the name of the risk function to use, and any parameters it requires\n",
    "    - a risk limit for each contest to be audited\n",
    "    - the social choice function for each contest, including the number of winners\n",
    "    - candidate identifiers\n",
    "+ a ballot manifest**\n",
    "+ a random seed\n",
    "+ reported results for each contest\n",
    "+ json files of assertions for IRV contests (one file per IRV contest)\n",
    "+ human reading of voter intent from the paper cards selected for audit\n",
    "\n",
    "** The ballot manifest could be for cards purported to contain the contests under audit (manifest_type == \"STYLE\"), or could include cards that might not contain the contest (manifest_type == \"ALL\"). These are treated differently. If the sample is to be drawn only from cards that--according to the manifest--contain the contest, and a sampled card turns out not to contain the contest, that is considered a discrepancy, dealt with using the \"phantoms to zombies\" approach. It is assumed that every card in the manifest corresponds to a ballot casted, but there might be ballots casted with no corresponding manifest entry. In that case, phantom records are created to ensure that the audit is still truly risk-limiting. \n",
    "\n",
    "Given an independent (i.e., not relying on the voting system) upper bound on the number of cards that contain the contest, if the number of manifest entries that contain the contest does not exceed that bound, we can sample from paper purported to contain the contest and use the \"zombies\" approach (Banuelos & Stark) to deal with missing manifest entries. This can greatly increase the efficiency of the audit if the contest is on only a small percentage of the cast cards.\n",
    "\n",
    "Any sampled phantom card (i.e., a card for which there is no manifest entry) is treated as if its MVR was least favorable (a \"zombie\" producing the greatest doubt in every assertion, separately). Any sampled manifest entry for which there is no corresponding MVR that contains the contest is treated in the least favorable way for each assertion (i.e., as a zombie rather than a non-vote). The least favorable outcome for a ballot in a ballot polling audit is a valid vote for every loser. \n",
    "\n",
    "This tool helps select cards for audit, and reports when the audit has found sufficient strong evidence to stop. \n",
    "\n",
    "The tool exports a log of all the audit inputs, including the auditors' manually determined voter intent from the audited cards. \n",
    "\n",
    "The current version uses a single sample to audit all contests. It is possible to refine things to target smaller contests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cryptorandom.cryptorandom import SHA256\n",
    "from cryptorandom.sample import sample_by_index\n",
    "\n",
    "from assertion_audit_utils import \\\n",
    "    Assertion, Assorter, CVR, TestNonnegMean, check_audit_parameters,\\\n",
    "    find_p_values, find_sample_size, new_sample_size, summarize_status,\\\n",
    "    write_audit_parameters\n",
    "from dominion_tools import \\\n",
    "    prep_dominion_manifest, sample_from_manifest, write_cards_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit parameters.\n",
    "\n",
    "* `seed`: the numeric seed for the pseudo-random number generator used to draw sample \n",
    "* `replacement`: whether to sample with replacement. If the sample is drawn with replacement, gamma must also be specified.\n",
    "* `risk_function`: the function to be used to measure risk. Options are `kaplan_markov`,`kaplan_wald`,`kaplan_kolmogorov`,`wald_sprt`,`kaplan_martingale`. Not all risk functions work with every social choice function. `wald_sprt` applies only to plurality contests.\n",
    "* `g`: a parameter to hedge against the possibility of observing a maximum overstatement. Require $g \\in [0, 1)$ for `kaplan_kolmogorov`, `kaplan_markov`, and `kaplan_wald`.\n",
    "* `N_cards`: an upper bound on the number of pieces of paper cast in the contest. This should be derived independently of the voting system. A ballot consists of one or more cards.\n",
    "\n",
    "----\n",
    "\n",
    "* `manifest_file`: filename for ballot manifest (input)\n",
    "* `manifest_type`: \"STYLE\" if the manifest is supposed to list only cards that contain the contests under audit; \"ALL\" if the manifest contains all cards cast in the election\n",
    "* `assertion_file`: filename of assertions for IRV contests, in RAIRE format (input)\n",
    "* `sample_file`: filename for sampled card identifiers (output)\n",
    "* `mvr_file`: filename for manually ascertained votes from sampled cards (input)\n",
    "* `log_file`: filename for audit log (output)\n",
    "\n",
    "----\n",
    "\n",
    "* `contests`: a dict of contest-specific data \n",
    "    + the keys are unique contest identifiers for contests under audit\n",
    "    + the values are dicts with keys:\n",
    "        - `risk_limit`: the risk limit for the audit of this contest\n",
    "        - `choice_function`: `plurality`, `supermajority`, or `IRV`\n",
    "        - `n_winners`: number of winners for majority contests. (Multi-winner IRV not supported; multi-winner super-majority is nonsense)\n",
    "        - `share_to_win`: for super-majority contests, the fraction of valid votes required to win, e.g., 2/3.\n",
    "        - `candidates`: list of names or identifiers of candidates\n",
    "        - `reported_winners` : list of identifier(s) of candidate(s) reported to have won. Length should equal `n_winners`.\n",
    "        - `assertion_file`: filename for a set of json descriptors of Assertions (see technical documentation) that collectively imply the reported outcome of the contest is correct. Required for IRV; ignored for other social choice functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20546205145833673229  # use, e.g., 20 rolls of a 10-sided die. Seed doesn't have to be numeric\n",
    "replacement = False\n",
    "\n",
    "#risk_function = \"kaplan_martingale\"\n",
    "#risk_fn = lambda x: TestNonnegMean.kaplan_martingale(x, N=N_cards)[0]\n",
    "\n",
    "risk_function = \"kaplan_kolmogorov\"\n",
    "risk_fn = lambda x: TestNonnegMean.kaplan_kolmogorov(x, N=N_cards, t=1/2, g=g)\n",
    "\n",
    "g = 0.5\n",
    "N_cards = 300000 # Upper bound on number of ballots cast \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_file = './Data/N19 ballot manifest with WH location for RLA Upload VBM 11-14.xlsx'\n",
    "manifest_type = 'STYLE' # every card should contain the contest #'ALL' not supported yet\n",
    "sample_file = './Data/sample_polling.csv'\n",
    "mvr_file = './Data/mvr_prepilot_test.json'\n",
    "log_file = './Data/log_polling.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit. Edit with details of your contest (eg., Contest 339 is the DA race)\n",
    "contests = {'339':{'risk_limit': 0.05,\n",
    "                     'choice_function':'IRV',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['15','16','17','18'],\n",
    "                     'reported_winners' : ['15'],\n",
    "                     'assertion_file' : './Data/SF2019Nov8Assertions.json'\n",
    "                    }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of other social choice functions:\n",
    "\n",
    "> contests =  {'city_council':{'risk_limit':0.05,\n",
    "                     'choice_function':'plurality',\n",
    "                     'n_winners':3,\n",
    "                     'candidates':['Doug','Emily','Frank','Gail','Harry'],\n",
    "                     'reported_winners' : ['Doug', 'Emily', 'Frank']\n",
    "                    },\n",
    "            'measure_1':{'risk_limit':0.05,\n",
    "                     'choice_function':'supermajority',\n",
    "                     'share_to_win':2/3,\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['yes','no'],\n",
    "                     'reported_winners' : ['yes']\n",
    "                    }                  \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c]['choice_function'] == 'IRV':\n",
    "        with open(contests[c]['assertion_file'], 'r') as f:\n",
    "            contests[c]['assertion_json'] = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "all_assertions = Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the ballot manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Tray # Tabulator Number Batch Number  Total Ballots VBMCart.Cart number  \\\n0         1            99808           78            116                   3   \n1         1            99808           77            115                   3   \n2         1            99808           79            120                   3   \n3         1            99808           81             76                   3   \n4         1            99808           80            116                   3   \n...     ...              ...          ...            ...                 ...   \n5477   3506            99815           84            222                  19   \n5478   3506            99815           83            346                  19   \n5479   3506            99815           82            332                  19   \n5480   3507            99802          822             98                  14   \n5481   None          phantom            1           6445                None   \n\n      cum_cards  \n0           116  \n1           231  \n2           351  \n3           427  \n4           543  \n...         ...  \n5477     292779  \n5478     293125  \n5479     293457  \n5480     293555  \n5481     300000  \n\n[5482 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tray #</th>\n      <th>Tabulator Number</th>\n      <th>Batch Number</th>\n      <th>Total Ballots</th>\n      <th>VBMCart.Cart number</th>\n      <th>cum_cards</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>99808</td>\n      <td>78</td>\n      <td>116</td>\n      <td>3</td>\n      <td>116</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>99808</td>\n      <td>77</td>\n      <td>115</td>\n      <td>3</td>\n      <td>231</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>99808</td>\n      <td>79</td>\n      <td>120</td>\n      <td>3</td>\n      <td>351</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>99808</td>\n      <td>81</td>\n      <td>76</td>\n      <td>3</td>\n      <td>427</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>99808</td>\n      <td>80</td>\n      <td>116</td>\n      <td>3</td>\n      <td>543</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5477</th>\n      <td>3506</td>\n      <td>99815</td>\n      <td>84</td>\n      <td>222</td>\n      <td>19</td>\n      <td>292779</td>\n    </tr>\n    <tr>\n      <th>5478</th>\n      <td>3506</td>\n      <td>99815</td>\n      <td>83</td>\n      <td>346</td>\n      <td>19</td>\n      <td>293125</td>\n    </tr>\n    <tr>\n      <th>5479</th>\n      <td>3506</td>\n      <td>99815</td>\n      <td>82</td>\n      <td>332</td>\n      <td>19</td>\n      <td>293457</td>\n    </tr>\n    <tr>\n      <th>5480</th>\n      <td>3507</td>\n      <td>99802</td>\n      <td>822</td>\n      <td>98</td>\n      <td>14</td>\n      <td>293555</td>\n    </tr>\n    <tr>\n      <th>5481</th>\n      <td>None</td>\n      <td>phantom</td>\n      <td>1</td>\n      <td>6445</td>\n      <td>None</td>\n      <td>300000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5482 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Read manifest\n",
    "manifest = pd.read_excel(manifest_file)\n",
    "\n",
    "# Add phantoms if necessary\n",
    "manifest, manifest_cards, phantom_cards = prep_dominion_manifest(manifest, N_cards)\n",
    "\n",
    "manifest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, \\\n",
    "                        contests, N_cards, manifest_cards, phantom_cards)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use initial_sample_size function to calculate\n",
    "# w/ alpha=0.05, winning proportion ~ 0.58 (ASN formula)\n",
    "sample_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The sample includes 1 phantom cards.\n"
    }
   ],
   "source": [
    "prng = SHA256(seed)\n",
    "sample = sample_by_index(N_cards, sample_size, prng=prng)\n",
    "n_phantom_sample = np.sum([i>manifest_cards for i in sample]) \n",
    "print(\"The sample includes {} phantom cards.\".format(n_phantom_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manifest_sample_lookup = sample_from_manifest(manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cards_sampled(sample_file, manifest_sample_lookup, print_phantoms=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the audited sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "id: 99807-3-2 votes: {'339': {'16': 3, '17': 2, '18': 1}} phantom: False\nid: 99809-27-41 votes: {'339': {'15': 3, '16': 1, '17': 4, '18': 2}} phantom: False\nid: 99807-4-20 votes: {'339': {'15': 1, '17': 2}} phantom: False\nid: 99805-68-45 votes: {'339': {'15': 4, '16': 1, '17': 2, '18': 3}} phantom: False\nid: 99805-30-44 votes: {'339': {'15': 3, '16': 2, '17': 1, '18': 4}} phantom: False\nid: 99805-30-89 votes: {'339': {'15': 2, '17': 1}} phantom: False\nid: 99808-28-57 votes: {'339': {'17': 1}} phantom: False\nid: 99811-26-37 votes: {'339': {'18': 1}} phantom: False\nid: 99804-19-38 votes: {'339': {'15': 2, '18': 1}} phantom: False\nid: 99802-15-23 votes: {'339': {'15': 3, '16': 4, '17': 1, '18': 2}} phantom: False\n"
    }
   ],
   "source": [
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])\n",
    "\n",
    "for i in range(10):\n",
    "    print(mvr_sample[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "maximum assertion p-value 1.0\np-values for assertions in contest 339\n18 v 17 elim 15 16 45 0.44444592593086424\n17 v 16 elim 15 18 45 0.16442065403052356\n15 v 18 elim 16 17 45 1\n18 v 16 elim 15 17 45 0.18177495204054053\n17 v 16 elim 15 45 0.12331302403563205\n15 v 17 elim 16 45 0.666671111140741\n15 v 17 elim 16 18 45 0.8888933333580249\n18 v 16 elim 15 45 0.0006393433634743348\n15 v 16 elim 17 45 0.03551102651343496\n15 v 16 elim 17 18 45 0.6158738145782814\n15 v 16 elim 18 45 0.0006720045032241711\n15 v 16 elim 45 0.00043121861510718234\n15 v 45 2.694246027008499e-11\n\ncontest 339 audit INCOMPLETE at risk limit 0.05. Attained risk 1.0\nassertions remaining to be proved:\n18 v 17 elim 15 16 45: current risk 0.44444592593086424\n17 v 16 elim 15 18 45: current risk 0.16442065403052356\n15 v 18 elim 16 17 45: current risk 1\n18 v 16 elim 15 17 45: current risk 0.18177495204054053\n17 v 16 elim 15 45: current risk 0.12331302403563205\n15 v 17 elim 16 45: current risk 0.666671111140741\n15 v 17 elim 16 18 45: current risk 0.8888933333580249\n15 v 16 elim 17 18 45: current risk 0.6158738145782814\n"
    }
   ],
   "source": [
    "p_max = find_p_values(contests, all_assertions, risk_fn, manifest_type, mvr_sample)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests, all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit\n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, \\\n",
    "                        contests, N_cards,  manifest_cards, phantom_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many more cards should be audited?\n",
    "\n",
    "Estimate how many more cards will need to be audited to confirm any remaining contests. The enlarged sample size is based on:\n",
    "\n",
    "* cards already sampled\n",
    "* the assumption that we will continue to see errors at the same rate observed in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_size, sams = new_sample_size(contests, all_assertions, risk_fn, manifest_type, \\\n",
    "                                    mvr_sample,cvr_sample=None, quantile=0.8, reps=10)\n",
    "print(new_size, sams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the sample\n",
    "# reset the seed\n",
    "prng = SHA256(seed)\n",
    "old_sample = sample\n",
    "sample = sample_by_index(N_cards, new_size, prng=prng)\n",
    "incremental_sample = np.sort(list(set(sample) - set(old_sample)))\n",
    "n_phantom_sample = np.sum([i>manifest_cards for i in incremental_sample])\n",
    "print(\"The incremental sample includes {} phantom cards.\".format(n_phantom_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_sample_lookup_new = sample_from_manifest(manifest, incremental_sample)\n",
    "write_cards_sampled(sample_file, manifest_sample_lookup, print_phantoms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mvr_json should contain the complete set of mvrs, including those in previous rounds\n",
    "\n",
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile entire sample\n",
    "manifest_sample_lookup = sample_from_manifest(manifest, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_max = find_p_values(contests, all_assertions, risk_fn, mvr_sample)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests, all_assertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit\n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, \\\n",
    "                        contests, N_cards,  manifest_cards, phantom_cards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}