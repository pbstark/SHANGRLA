{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assertion RLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From 18 May 2022, consistent sampling seems to be working.**\n",
    "\n",
    "**From 1 April 2022, integrating alpha_mart, p_history, and other features.**\n",
    "\n",
    "**From 24 October 2021, dev version implementing consistent sampling to target smaller contests.**\n",
    "\n",
    "## Overview of the assertion audit tool\n",
    "\n",
    "The tool requires as input:\n",
    "\n",
    "+ audit-specific and contest-specific parameters, such as\n",
    "    - whether to sample with or without replacement\n",
    "    - the name of the risk function to use, and any parameters it requires\n",
    "    - a risk limit for each contest to be audited\n",
    "    - the social choice function for each contest, including the number of winners\n",
    "    - candidate identifiers for each contest\n",
    "    - an upper bound on the number of ballot cards that contain each contest\n",
    "    - an upper bound on the total number of cards across all contests\n",
    "    - whether to use card style information to target sampling\n",
    "+ a ballot manifest (see below)\n",
    "+ a random seed\n",
    "+ a file of cast vote records\n",
    "+ reported results for each contest\n",
    "+ json files of assertions for IRV contests (one file per IRV contest)\n",
    "+ human reading of voter intent from the paper cards selected for audit\n",
    "\n",
    "`use_style` controls whether the sample is drawn from all cards (`use_style == False`) or card style information is used\n",
    "to target the cards that purport to contain each contest (`use_style == True`).\n",
    "In the current implementation, card style information is inferred from cast-vote records, with additional 'phantom' CVRs if there could be more cards that contain a contest than is accounted for in the CVRs.\n",
    "Errors in the card style information are treated conservatively using the  \"phantoms-to-evil-zombies\" (~2EZ) approach ([Banuelos & Stark, 2012](https://arxiv.org/abs/1207.3413)) so that the risk limit remains valid, even if the CVRs misrepresent\n",
    "which cards contain which contests.\n",
    "\n",
    "The two ways of sampling are treated differently. \n",
    "If the sample is to be drawn only from cards that--according to the CVR--contain a particular contest, and a sampled card turns out not to\n",
    "contain that contest, that is considered a discrepancy, dealt with using the ~2EZ approach.\n",
    "It is assumed that every CVR corresponds to a card in the manifest, but there might\n",
    "be cards cast in the contest for which there is no corresponding CVR. In that case,\n",
    "phantom records are created to ensure that the audit is still truly risk-limiting.\n",
    "\n",
    "Given an independent (i.e., not relying on the voting system) upper bound on the number of cards that contain the contest, if the number of CVRs that contain the contest does not exceed that bound, we can sample from paper purported to contain the contest and use the ~2EZ approach to deal with missing CVRs. This can greatly increase the efficiency of the audit if \n",
    "some contests appear on only a small percentage of the cast cards ([Glazer, Spertus, and Stark (2021)](https://dl.acm.org/doi/10.1145/3457907)).\n",
    "\n",
    "Any sampled phantom card (i.e., a card for which there is no CVR) is treated as if its CVR is a non-vote (which it is), and as if its MVR was least favorable (an \"evil zombie\" producing the greatest doubt in every assertion, separately). Any sampled card for which there is a CVR is compared to its corresponding CVR. \n",
    "If the card turns out not to contain the contest (despite the fact that the CVR says it does), the MVR is treated in the least favorable way for each assertion (i.e., as a zombie rather than as a non-vote).\n",
    "\n",
    "The tool helps select cards for audit, and reports when the audit has found sufficiently strong evidence to stop.\n",
    "\n",
    "The tool exports a log of all the audit inputs except the CVR file, but including the auditors' manually determined voter intent from the audited cards.\n",
    "\n",
    "The pre-10/2021 version used a single sample to audit all contests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal workflow\n",
    "\n",
    "+ Read overall audit information and contest information, and random seed\n",
    "+ Read assertions for IRV contests and construct assertions for all other contests\n",
    "+ Read ballot manifest\n",
    "+ Read cvrs. Every CVR should have a corresponding manifest entry.\n",
    "+ Prepare ~2EZ:\n",
    "    - `N_phantoms = max_cards - cards_in_manifest`\n",
    "    - If `N_phantoms < 0`, complain\n",
    "    - Else create `N_phantoms` phantom cards\n",
    "    - For each contest `c`:\n",
    "        + `N_c` is the input upper bound on the number of cards that contain `c`\n",
    "        + if `N_c is None`, `N_c = max_cards - non_c_cvrs`, where `non_c_cvrs` is #CVRs that don't contain `c`\n",
    "        + `C_c` is the number of CVRs that contain the contest\n",
    "        + if `C_c > N_c`, complain\n",
    "        + else if `N_c - C_c > N_phantoms`, complain\n",
    "        + else:\n",
    "            - Consider contest `c` to be on the first `N_c - C_c` phantom CVRs\n",
    "            - Consider contest `c` to be on the first `N_c - C_c` phantom ballots\n",
    "+ Calculate assorter margins for all assorters:\n",
    "    - If `not use_style`, apply the assorter to all cards and CVRs, including phantoms\n",
    "    - Else apply the assorter only to cards/cvrs reported to contain the contest, including phantoms that contain the contest\n",
    "+ Estimate starting sample size for the specified sampling design (w/ or w/o replacement, stratified, etc.), for chosen risk function:\n",
    "    - User-specified criterion, controlled by parameters. Examples:\n",
    "        + expected sample size for completion, on the assumption that there are no errors\n",
    "        + 90th percentile of sample size for completion, on the assumption that errors are not more frequent than specified\n",
    "    - If `not use_style`, base estimate on sampling from the entire manifest, i.e., smallest assorter margin\n",
    "    - Else use consistent sampling:\n",
    "        + Augment each CVR (including phantoms) with a probability of selection, `p`, initially 0\n",
    "        + For each contest `c`:\n",
    "            - Find sample size `n_c` that meets the criterion \n",
    "            - For each non-phantom CVR that contains the contest, set `p = max(p, n_c/N_c)` \n",
    "        + Estimated sample size is the sum of `p` over all non-phantom CVRs\n",
    "+ Draw the random sample:\n",
    "    - Use specified design, with consistent sampling for style information\n",
    "    - Express sample cards in terms of the manifest\n",
    "    - Export\n",
    "+ Read manual interpretations of the cards (MVRs)\n",
    "+ Calculate attained risk for each assorter\n",
    "    - Use ~2EZ to deal with phantom CVRs or cards; the treatment depends on whether `use_style == True`\n",
    "+ Report\n",
    "+ Estimate incremental sample size if any assorter nulls have not been rejected\n",
    "+ Draw incremental sample; etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cryptorandom.cryptorandom import SHA256, int_from_hash\n",
    "from cryptorandom.sample import sample_by_index\n",
    "\n",
    "from assertion_audit_utils import \\\n",
    "    Assertion, Assorter, CVR, TestNonnegMean, check_audit_parameters, find_margins,\\\n",
    "    find_p_values, initial_sample_size, find_sample_size, new_sample_size, prep_comparison_sample, \\\n",
    "    prep_polling_sample, summarize_status, write_audit_parameters\n",
    "from dominion_tools import \\\n",
    "    prep_manifest, sample_from_cvrs, sample_from_manifest, write_cards_sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audit parameters.\n",
    "\n",
    "* `seed`: the numeric seed for the pseudo-random number generator used to draw sample \n",
    "* `replacement`: whether to sample with replacement. If the sample is drawn with replacement, gamma must also be specified.\n",
    "* `risk_function`: the name of the function to be used to measure risk. Options are `kaplan_markov`,`kaplan_wald`,`kaplan_kolmogorov`,`wald_sprt`,`kaplan_mart`, `alpha_mart`. \n",
    "Not all risk functions work with every social choice function. \n",
    "* `g`: a parameter to hedge against the possibility of observing a maximum overstatement. Require $g \\in [0, 1)$ for `kaplan_kolmogorov`, `kaplan_markov`, and `kaplan_wald`.\n",
    "* **TO DO** pass an estimator with `alpha_mart`. Perhaps generalize `g` so it can be callable, not just real\n",
    "* `max_cards`: an upper bound on the number of pieces of paper cast in the contest. This should be derived independently of the voting system. A ballot consists of one or more cards.\n",
    "\n",
    "----\n",
    "\n",
    "* `cvr_file`: filename for CVRs (input)\n",
    "* `manifest_file`: filename for ballot manifest (input)\n",
    "* `use_style`: Boolean. If True, use card style information (inferred from CVRs) to target samples. If False, sample from all cards, regardless of the contest.\n",
    "* `assertion_file`: filename of assertions for IRV contests, in RAIRE format (input)\n",
    "* `sample_file`: filename for sampled card identifiers (output)\n",
    "* `mvr_file`: filename for manually ascertained votes from sampled cards (input)\n",
    "* `log_file`: filename for audit log (output)\n",
    "\n",
    "----\n",
    "\n",
    "* `error_rate`: expected rate of 1-vote overstatements. Recommended value $\\ge$ 0.001 if there are hand-marked ballots. Larger values increase the initial sample size, but make it more likely that the audit will conclude in a single round if the audit finds errors\n",
    "\n",
    "* `contests`: a dict of contest-specific data \n",
    "    + the keys are unique contest identifiers for contests under audit\n",
    "    + the values are dicts with keys:\n",
    "        - `risk_limit`: the risk limit for the audit of this contest\n",
    "        - `cards`: an upper bound on the number of cast cards that contain the contest\n",
    "        - `choice_function`: `plurality`, `supermajority`, or `IRV`\n",
    "        - `n_winners`: number of winners for majority contests. (Multi-winner IRV not supported)\n",
    "        - `share_to_win`: for super-majority contests, the fraction of valid votes required to win, e.g., 2/3. share_to_win*n_winners must be less than 100%)\n",
    "        - `candidates`: list of names or identifiers of candidates\n",
    "        - `reported_winners` : list of identifier(s) of candidate(s) reported to have won. Length should equal `n_winners`.\n",
    "        - `assertion_file`: filename for a set of json descriptors of Assertions (see technical documentation) that collectively imply the reported outcome of the contest is correct. Required for IRV; ignored for other social choice functions\n",
    "        - other keys and values are added by the software, including `cvrs`, the number of CVRs that contain the contest, and `p`, the sampling fraction expected to be required to confirm the contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345678901234567890  # use, e.g., 20 rolls of a 10-sided die. Seed doesn't have to be numeric\n",
    "replacement = False\n",
    "\n",
    "# implied value of eta for margin m is eta=(m+1)/2\n",
    "risk_function = \"alpha_mart\"\n",
    "risk_fn = lambda x, m, N: TestNonnegMean.alpha_mart(x, eta=(m+1)/2 , N=N)\n",
    "\n",
    "# Other options for the risk function:\n",
    "\n",
    "# risk_function = \"kaplan_mart\"\n",
    "# risk_fn = lambda x, m, N: TestNonnegMean.kaplan_mart(x, N)\n",
    "\n",
    "# risk_function = \"kaplan_kolmogorov\"\n",
    "# risk_fn = lambda x, m, N: TestNonnegMean.kaplan_kolmogorov(x, N, g=g)\n",
    "\n",
    "g=0.1\n",
    "max_cards = 293555 # 146662 VBM turnout per SF Elections release 12\n",
    "        # https://sfelections.sfgov.org/november-5-2019-election-results-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_file = './Data/SFDA2019_PrelimReport12VBMJustDASheets.raire'\n",
    "manifest_file = './Data/N19 ballot manifest with WH location for RLA Upload VBM 11-14.xlsx'\n",
    "use_style = 'True'  # every card should contain the contest\n",
    "sample_file = './Data/sample.csv'\n",
    "# mvr_file = './Data/mvr_prepilot_test.json'\n",
    "# mvr_file = './Data/mvrTest-PR12-DA-VBM-AllBallots-4TargetedErrors.json'\n",
    "mvr_file = './Data/mvr.json'\n",
    "log_file = './Data/log.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = 0.002   # to estimate sample sizes for comparison audits, 2 1-vote overstatements per 1000 ballots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contests to audit. Edit with details of your contest (eg., Contest 339 is the DA race)\n",
    "contests = {'339':{'risk_limit':0.05,\n",
    "                     'cards': 146662,\n",
    "                     'choice_function':'IRV',\n",
    "                     'n_winners':1,\n",
    "                     'candidates':['15','16','17','18'],\n",
    "                     'reported_winners' : ['15'],\n",
    "                     'assertion_file' : './Data/SF2019Nov8Assertions.json'\n",
    "                    }\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of other social choice functions:\n",
    "\n",
    "        contests =  {'city_council':{'risk_limit':0.05,\n",
    "                             'cards': None,\n",
    "                             'choice_function':'plurality',\n",
    "                             'n_winners':3,\n",
    "                             'candidates':['Doug','Emily','Frank','Gail','Harry'],\n",
    "                             'reported_winners' : ['Doug', 'Emily', 'Frank']\n",
    "                            },\n",
    "                        'measure_1':{'risk_limit':0.05,\n",
    "                             'cards': 65432,\n",
    "                             'choice_function':'supermajority',\n",
    "                             'share_to_win':2/3,\n",
    "                             'n_winners':1,\n",
    "                             'candidates':['yes','no'],\n",
    "                             'reported_winners' : ['yes']\n",
    "                            }                  \n",
    "                      }\n",
    "              \n",
    "If `cards` is `None`, uses `max_cards` as the upper bound for the contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the assertions for the IRV contest\n",
    "for c in contests:\n",
    "    if contests[c]['choice_function'] == 'IRV':\n",
    "        with open(contests[c]['assertion_file'], 'r') as f:\n",
    "            contests[c]['assertion_json'] = json.load(f)['audits'][0]['assertions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the dict of dicts of assertions for each contest\n",
    "Assertion.make_all_assertions(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339\n",
      "{'18 v 17 elim 15 16 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9af0>, '17 v 16 elim 15 18 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee96d0>, '15 v 18 elim 16 17 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9880>, '18 v 16 elim 15 17 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee97c0>, '17 v 16 elim 15 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9f70>, '15 v 17 elim 16 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9100>, '15 v 17 elim 16 18 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee98b0>, '18 v 16 elim 15 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9610>, '15 v 16 elim 17 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9490>, '15 v 16 elim 17 18 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9310>, '15 v 16 elim 18 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee93a0>, '15 v 16 elim 45': <assertion_audit_utils.Assertion object at 0x7fd99064b7f0>, '15 v 45': <assertion_audit_utils.Assertion object at 0x7fd99064bcd0>}\n"
     ]
    }
   ],
   "source": [
    "for c in contests:\n",
    "    print(f'{c}\\n{contests[c][\"assertions\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the ballot manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special for Primary/Dominion manifest format\n",
    "manifest = pd.read_excel(manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CVRs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 146664 rows\n"
     ]
    }
   ],
   "source": [
    "# for ballot-level comparison audits\n",
    "\n",
    "cvr_input = []\n",
    "with open(cvr_file) as f:\n",
    "    cvr_reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    for row in cvr_reader:\n",
    "        cvr_input.append(row)\n",
    "\n",
    "print(\"Read {} rows\".format(len(cvr_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging, there are CVRs for 146662 cards\n"
     ]
    }
   ],
   "source": [
    "# Import/convert CVRs\n",
    "cvr_list = CVR.from_raire(cvr_input)\n",
    "print(\"After merging, there are CVRs for {} cards\".format(len(cvr_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn RAIRE-style card identifiers into Dominion's style by substituting \"-\" for \"_\"\n",
    "for c in cvr_list:\n",
    "    c.set_id(str(c.id).replace(\"_\",\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 99813-1-1 votes: {'339': {'17': 1}} phantom: False\n",
      "id: 99813-1-3 votes: {'339': {'16': 1}} phantom: False\n",
      "id: 99813-1-6 votes: {'339': {'18': 1, '17': 2, '15': 3, '16': 4}} phantom: False\n",
      "id: 99813-1-8 votes: {'339': {'18': 1}} phantom: False\n",
      "id: 99813-1-9 votes: {'339': {'': 1}} phantom: False\n",
      "id: 99813-1-11 votes: {'339': {'16': 1, '17': 2, '15': 3, '18': 4}} phantom: False\n",
      "id: 99813-1-13 votes: {'339': {'15': 1, '16': 2, '17': 3, '18': 4}} phantom: False\n",
      "id: 99813-1-16 votes: {'339': {'15': 1}} phantom: False\n",
      "id: 99813-1-17 votes: {'339': {'15': 1}} phantom: False\n",
      "id: 99813-1-19 votes: {'339': {'16': 1}} phantom: False\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(str(cvr_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'339': {'risk_limit': 0.05,\n",
       "  'cards': 146662,\n",
       "  'choice_function': 'IRV',\n",
       "  'n_winners': 1,\n",
       "  'candidates': ['15', '16', '17', '18'],\n",
       "  'reported_winners': ['15'],\n",
       "  'assertion_file': './Data/SF2019Nov8Assertions.json',\n",
       "  'assertion_json': [{'winner': '18',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['15', '16', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 17]'},\n",
       "   {'winner': '17',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 17 16]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '18',\n",
       "    'already_eliminated': ['16', '17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 18]'},\n",
       "   {'winner': '18',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 16]'},\n",
       "   {'winner': '17',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 17 16 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['16', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 17 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['16', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 17]'},\n",
       "   {'winner': '18',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 16 17]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['17', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 17]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 17 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '45',\n",
       "    'already_eliminated': '',\n",
       "    'assertion_type': 'WINNER_ONLY',\n",
       "    'explanation': 'Rules out case where 15 is eliminated before 45'}],\n",
       "  'assertions': {'18 v 17 elim 15 16 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9af0>,\n",
       "   '17 v 16 elim 15 18 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee96d0>,\n",
       "   '15 v 18 elim 16 17 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9880>,\n",
       "   '18 v 16 elim 15 17 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee97c0>,\n",
       "   '17 v 16 elim 15 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9f70>,\n",
       "   '15 v 17 elim 16 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9100>,\n",
       "   '15 v 17 elim 16 18 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee98b0>,\n",
       "   '18 v 16 elim 15 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9610>,\n",
       "   '15 v 16 elim 17 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9490>,\n",
       "   '15 v 16 elim 17 18 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9310>,\n",
       "   '15 v 16 elim 18 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee93a0>,\n",
       "   '15 v 16 elim 45': <assertion_audit_utils.Assertion at 0x7fd99064b7f0>,\n",
       "   '15 v 45': <assertion_audit_utils.Assertion at 0x7fd99064bcd0>}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293555, 293555)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether the manifest accounts for every card\n",
    "max_cards, np.sum(manifest['Total Ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tray #</th>\n",
       "      <th>Tabulator Number</th>\n",
       "      <th>Batch Number</th>\n",
       "      <th>Total Ballots</th>\n",
       "      <th>VBMCart.Cart number</th>\n",
       "      <th>cum_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>78</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>77</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>79</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>99808</td>\n",
       "      <td>80</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>3506</td>\n",
       "      <td>99815</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>292557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5477</th>\n",
       "      <td>3506</td>\n",
       "      <td>99815</td>\n",
       "      <td>84</td>\n",
       "      <td>222</td>\n",
       "      <td>19</td>\n",
       "      <td>292779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5478</th>\n",
       "      <td>3506</td>\n",
       "      <td>99815</td>\n",
       "      <td>83</td>\n",
       "      <td>346</td>\n",
       "      <td>19</td>\n",
       "      <td>293125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5479</th>\n",
       "      <td>3506</td>\n",
       "      <td>99815</td>\n",
       "      <td>82</td>\n",
       "      <td>332</td>\n",
       "      <td>19</td>\n",
       "      <td>293457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5480</th>\n",
       "      <td>3507</td>\n",
       "      <td>99802</td>\n",
       "      <td>822</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>293555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5481 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tray # Tabulator Number Batch Number  Total Ballots VBMCart.Cart number  \\\n",
       "0         1            99808           78            116                   3   \n",
       "1         1            99808           77            115                   3   \n",
       "2         1            99808           79            120                   3   \n",
       "3         1            99808           81             76                   3   \n",
       "4         1            99808           80            116                   3   \n",
       "...     ...              ...          ...            ...                 ...   \n",
       "5476   3506            99815           86              2                  19   \n",
       "5477   3506            99815           84            222                  19   \n",
       "5478   3506            99815           83            346                  19   \n",
       "5479   3506            99815           82            332                  19   \n",
       "5480   3507            99802          822             98                  14   \n",
       "\n",
       "      cum_cards  \n",
       "0           116  \n",
       "1           231  \n",
       "2           351  \n",
       "3           427  \n",
       "4           543  \n",
       "...         ...  \n",
       "5476     292557  \n",
       "5477     292779  \n",
       "5478     293125  \n",
       "5479     293457  \n",
       "5480     293555  \n",
       "\n",
       "[5481 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that there is a card in the manifest for every card (possibly) cast. If not, add phantoms.\n",
    "manifest, manifest_cards, phantom_cards = prep_manifest(manifest, max_cards, len(cvr_list))\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CVRs for phantom cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 0 phantom records\n"
     ]
    }
   ],
   "source": [
    "# For Comparison Audits Only\n",
    "#----------------------------\n",
    "\n",
    "# If the sample draws a phantom card, these CVRs will be used in the comparison.\n",
    "# phantom MVRs should be treated as zeros by the Assorter for every contest\n",
    "\n",
    "# setting use_style = False to generate phantoms\n",
    "\n",
    "cvr_list, phantom_vrs = CVR.make_phantoms(max_cards, cvr_list, contests, use_style=use_style, prefix='phantom-1-')\n",
    "print(f\"Created {phantom_vrs} phantom records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'339': {'risk_limit': 0.05,\n",
       "  'cards': 146662,\n",
       "  'choice_function': 'IRV',\n",
       "  'n_winners': 1,\n",
       "  'candidates': ['15', '16', '17', '18'],\n",
       "  'reported_winners': ['15'],\n",
       "  'assertion_file': './Data/SF2019Nov8Assertions.json',\n",
       "  'assertion_json': [{'winner': '18',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['15', '16', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 17]'},\n",
       "   {'winner': '17',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 17 16]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '18',\n",
       "    'already_eliminated': ['16', '17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 18]'},\n",
       "   {'winner': '18',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 16]'},\n",
       "   {'winner': '17',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 17 16 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['16', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 17 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '17',\n",
       "    'already_eliminated': ['16', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 17]'},\n",
       "   {'winner': '18',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['15', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 18 16 17]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['17', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['17', '18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['18', '45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 17]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '16',\n",
       "    'already_eliminated': ['45'],\n",
       "    'assertion_type': 'IRV_ELIMINATION',\n",
       "    'explanation': 'Rules out outcomes with tail [... 15 16 17 18]'},\n",
       "   {'winner': '15',\n",
       "    'loser': '45',\n",
       "    'already_eliminated': '',\n",
       "    'assertion_type': 'WINNER_ONLY',\n",
       "    'explanation': 'Rules out case where 15 is eliminated before 45'}],\n",
       "  'assertions': {'18 v 17 elim 15 16 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9af0>,\n",
       "   '17 v 16 elim 15 18 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee96d0>,\n",
       "   '15 v 18 elim 16 17 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9880>,\n",
       "   '18 v 16 elim 15 17 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee97c0>,\n",
       "   '17 v 16 elim 15 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9f70>,\n",
       "   '15 v 17 elim 16 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9100>,\n",
       "   '15 v 17 elim 16 18 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee98b0>,\n",
       "   '18 v 16 elim 15 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9610>,\n",
       "   '15 v 16 elim 17 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9490>,\n",
       "   '15 v 16 elim 17 18 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee9310>,\n",
       "   '15 v 16 elim 18 45': <assertion_audit_utils.Assertion at 0x7fd9e0ee93a0>,\n",
       "   '15 v 16 elim 45': <assertion_audit_utils.Assertion at 0x7fd99064b7f0>,\n",
       "   '15 v 45': <assertion_audit_utils.Assertion at 0x7fd99064bcd0>},\n",
       "  'cvrs': 146662}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum assorter margin 0.019902906001554532\n",
      "margins in contest 339\n",
      "18 v 17 elim 15 16 45 0.045792366120740224\n",
      "17 v 16 elim 15 18 45 0.019902906001554532\n",
      "15 v 18 elim 16 17 45 0.028923647570604505\n",
      "18 v 16 elim 15 17 45 0.0830003681935334\n",
      "17 v 16 elim 15 45 0.058079120699294995\n",
      "15 v 17 elim 16 45 0.08064120222007065\n",
      "15 v 17 elim 16 18 45 0.10951712099930444\n",
      "18 v 16 elim 15 45 0.14875018750596603\n",
      "15 v 16 elim 17 45 0.13548158350492967\n",
      "15 v 16 elim 17 18 45 0.1365247985163165\n",
      "15 v 16 elim 18 45 0.16666893946625572\n",
      "15 v 16 elim 45 0.15626406294745743\n",
      "15 v 45 0.2956457705472446\n"
     ]
    }
   ],
   "source": [
    "# find the mean of the assorters for the CVRs and check whether the assertions are met\n",
    "min_margin = find_margins(contests, cvr_list, use_style=use_style)\n",
    "\n",
    "print(\"minimum assorter margin {}\".format(min_margin))\n",
    "for c in contests:\n",
    "    print(\"margins in contest {}\".format(c))\n",
    "    for a, m in contests[c]['margins'].items():\n",
    "        print(a, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_audit_parameters(risk_function, g, error_rate, contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_file='./Data/log.json'\n",
      "seed=12345678901234567890\n",
      "replacement=False\n",
      "risk_function='alpha_mart'\n",
      "g=0.1\n",
      "max_cards=293555\n",
      "len(cvr_list)=146662\n",
      "manifest_cards=293555\n",
      "phantom_cards=0\n",
      "error_rate=0.002\n",
      "contests={'339': {'risk_limit': 0.05, 'cards': 146662, 'choice_function': 'IRV', 'n_winners': 1, 'candidates': ['15', '16', '17', '18'], 'reported_winners': ['15'], 'assertion_file': './Data/SF2019Nov8Assertions.json', 'assertion_json': [{'winner': '18', 'loser': '17', 'already_eliminated': ['15', '16', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 18 17]'}, {'winner': '17', 'loser': '16', 'already_eliminated': ['15', '18', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 17 16]'}, {'winner': '15', 'loser': '18', 'already_eliminated': ['16', '17', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 15 18]'}, {'winner': '18', 'loser': '16', 'already_eliminated': ['15', '17', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 18 16]'}, {'winner': '17', 'loser': '16', 'already_eliminated': ['15', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 17 16 18]'}, {'winner': '15', 'loser': '17', 'already_eliminated': ['16', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 15 17 18]'}, {'winner': '15', 'loser': '17', 'already_eliminated': ['16', '18', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 15 17]'}, {'winner': '18', 'loser': '16', 'already_eliminated': ['15', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 18 16 17]'}, {'winner': '15', 'loser': '16', 'already_eliminated': ['17', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 15 16 18]'}, {'winner': '15', 'loser': '16', 'already_eliminated': ['17', '18', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 15 16]'}, {'winner': '15', 'loser': '16', 'already_eliminated': ['18', '45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 15 16 17]'}, {'winner': '15', 'loser': '16', 'already_eliminated': ['45'], 'assertion_type': 'IRV_ELIMINATION', 'explanation': 'Rules out outcomes with tail [... 15 16 17 18]'}, {'winner': '15', 'loser': '45', 'already_eliminated': '', 'assertion_type': 'WINNER_ONLY', 'explanation': 'Rules out case where 15 is eliminated before 45'}], 'assertions': {'18 v 17 elim 15 16 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9af0>, '17 v 16 elim 15 18 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee96d0>, '15 v 18 elim 16 17 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9880>, '18 v 16 elim 15 17 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee97c0>, '17 v 16 elim 15 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9f70>, '15 v 17 elim 16 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9100>, '15 v 17 elim 16 18 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee98b0>, '18 v 16 elim 15 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9610>, '15 v 16 elim 17 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9490>, '15 v 16 elim 17 18 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee9310>, '15 v 16 elim 18 45': <assertion_audit_utils.Assertion object at 0x7fd9e0ee93a0>, '15 v 16 elim 45': <assertion_audit_utils.Assertion object at 0x7fd99064b7f0>, '15 v 45': <assertion_audit_utils.Assertion object at 0x7fd99064bcd0>}, 'cvrs': 146662, 'margins': {'18 v 17 elim 15 16 45': 0.045792366120740224, '17 v 16 elim 15 18 45': 0.019902906001554532, '15 v 18 elim 16 17 45': 0.028923647570604505, '18 v 16 elim 15 17 45': 0.0830003681935334, '17 v 16 elim 15 45': 0.058079120699294995, '15 v 17 elim 16 45': 0.08064120222007065, '15 v 17 elim 16 18 45': 0.10951712099930444, '18 v 16 elim 15 45': 0.14875018750596603, '15 v 16 elim 17 45': 0.13548158350492967, '15 v 16 elim 17 18 45': 0.1365247985163165, '15 v 16 elim 18 45': 0.16666893946625572, '15 v 16 elim 45': 0.15626406294745743, '15 v 45': 0.2956457705472446}}}\n"
     ]
    }
   ],
   "source": [
    "print(f'{log_file=}\\n{seed=}\\n{replacement=}\\n{risk_function=}\\n{g=}\\n{max_cards=}'\n",
    "      f'\\n{len(cvr_list)=}\\n{manifest_cards=}\\n{phantom_cards=}\\n{error_rate=}\\n{contests=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, max_cards, len(cvr_list), \\\n",
    "                      manifest_cards, phantom_cards, error_rate, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find initial sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_sample_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m ss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m m, r, N: TestNonnegMean\u001b[38;5;241m.\u001b[39minitial_sample_size(\\\n\u001b[1;32m      4\u001b[0m                         risk_function\u001b[38;5;241m=\u001b[39mrf, N\u001b[38;5;241m=\u001b[39mN, margin\u001b[38;5;241m=\u001b[39mm, polling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \\\n\u001b[1;32m      5\u001b[0m                         error_rate\u001b[38;5;241m=\u001b[39merror_rate, alpha\u001b[38;5;241m=\u001b[39mr, reps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;66;03m# change for comparison audits\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# debugging\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43minitial_sample_size\u001b[49m(risk_function\u001b[38;5;241m=\u001b[39mrf, N\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(cvr_list), margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \\\n\u001b[1;32m      9\u001b[0m                             polling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, \\\n\u001b[1;32m     10\u001b[0m                             t\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, u\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, reps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\\\n\u001b[1;32m     11\u001b[0m                             bias_up\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, quantile\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234567890\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     14\u001b[0m sample_size, sample_sizes \u001b[38;5;241m=\u001b[39m find_sample_size(contests, sample_size_function\u001b[38;5;241m=\u001b[39mss_fn, use_style\u001b[38;5;241m=\u001b[39muse_style, \\\n\u001b[1;32m     15\u001b[0m                                cvr_list\u001b[38;5;241m=\u001b[39mcvr_list)  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'initial_sample_size' is not defined"
     ]
    }
   ],
   "source": [
    "# find initial sample size\n",
    "rf = lambda x, m, N: risk_fn(x,m, N)[0]   # p_history is the second returned value\n",
    "ss_fn = lambda m, r, N: TestNonnegMean.initial_sample_size(\\\n",
    "                        risk_function=rf, N=N, margin=m, polling=False, \\\n",
    "                        error_rate=error_rate, alpha=r, reps=10) # change for comparison audits\n",
    "\n",
    "# debugging\n",
    "initial_sample_size(risk_function=rf, N=len(cvr_list), margin=0.1, \\\n",
    "                            polling=False, error_rate=0.001, alpha=0.05, \\\n",
    "                            t=1/2, u=1, reps=None,\\\n",
    "                            bias_up=True, quantile=0.5, seed=1234567890)\n",
    "\n",
    "# \n",
    "sample_size, sample_sizes = find_sample_size(contests, sample_size_function=ss_fn, use_style=use_style, \\\n",
    "                               cvr_list=cvr_list)  \n",
    "print(f'{sample_size=}\\n{sample_sizes=}')\n",
    "\n",
    "# override for testing\n",
    "sample_size = 20000\n",
    "print(sample_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Draw the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample includes 0 phantom cards.\n"
     ]
    }
   ],
   "source": [
    "# draw the initial sample\n",
    "sample_size = 146778\n",
    "prng = SHA256(seed)\n",
    "sample = sample_by_index(max_cards, sample_size, prng=prng) # 1-indexed\n",
    "n_phantom_sample = np.sum(sample > manifest_cards)\n",
    "print(f'The sample includes {n_phantom_sample} phantom cards.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146662, 293555, 293555)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvr_list), manifest_cards, max_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison audit\n",
    "# cards_to_retrieve, sample_order, cvr_sample, mvr_phantoms_sample = sample_from_cvrs(cvr_list, manifest, sample)\n",
    "\n",
    "# for polling audit\n",
    "cards_to_retrieve, sample_order, mvr_phantoms_sample = sample_from_manifest(manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the sample\n",
    "write_cards_sampled(sample_file, cards_to_retrieve, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the audited sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for real data\n",
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate ballot-polling data for testing/debugging, using the San Francisco IRV contest as an example\n",
    "mvr_sample = []\n",
    "for c in cvr_list:\n",
    "    if c in sample_order.keys():\n",
    "        mvr_sample.append(c)\n",
    "\n",
    "for s in set(sample_order.keys()) - set([c.id for c in mvr_sample]):\n",
    "    inx = np.random.randint(len(cvr_list))\n",
    "    mvr_sample.append(CVR(id = s, votes = cvr_list[inx].votes, phantom=False))\n",
    "\n",
    "print(f'simulated sample contains {len(mvr_sample)} mvrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_comparison_sample(mvr_sample, cvr_sample, sample_order)  # for comparison audit\n",
    "\n",
    "prep_polling_sample(mvr_sample, sample_order)  # for polling audit\n",
    "p_max = find_p_values(contests, mvr_sample, None, use_style, \\\n",
    "                      risk_function=risk_fn)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit \n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, max_cards, len(cvr_list), \\\n",
    "                       manifest_cards, phantom_cards, error_rate, contests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many more cards should be audited?\n",
    "\n",
    "Estimate how many more cards will need to be audited to confirm any remaining contests. The enlarged sample size is based on:\n",
    "\n",
    "* cards already sampled\n",
    "* the assumption that we will continue to see errors at the same rate observed in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvr_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/70/k4zn0z5907g_7ftxdq3dxm_h0000gn/T/ipykernel_59580/1952253186.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m new_size, sams = new_sample_size(contests, mvr_sample,\\\n\u001b[0;32m----> 5\u001b[0;31m                                  \u001b[0mcvr_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanifest_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                                  risk_fn, quantile=0.8, reps=100)\n\u001b[1;32m      7\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cvr_sample' is not defined"
     ]
    }
   ],
   "source": [
    "# Estimate sample size required to confirm the outcome, if errors continue\n",
    "# at the same rate as already observed.\n",
    "\n",
    "new_size, sams = new_sample_size(contests, mvr_sample,\\\n",
    "                                 cvr_sample, manifest_type,\\\n",
    "                                 risk_fn, quantile=0.8, reps=100)\n",
    "new_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the sample\n",
    "# reset the seed\n",
    "prng = SHA256(seed)\n",
    "old_sample = sample\n",
    "sample = sample_by_index(max_cards, new_size, prng=prng)\n",
    "incremental_sample = np.sort(list(set(sample) - set(old_sample)))\n",
    "n_phantom_sample = np.sum([cvr_list[i].phantom for i in incremental_sample])\n",
    "print(\"The incremental sample includes {} phantom cards.\".format(n_phantom_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvr_sample_lookup_new, cvr_sample_new, mvr_phantoms_sample_new = \\\n",
    "                sample_from_cvrs(cvr_list, manifest, incremental_sample)\n",
    "write_cards_sampled(sample_file, cvr_sample_lookup_new, print_phantoms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mvr_json should contain the complete set of mvrs, including those in previous rounds\n",
    "\n",
    "with open(mvr_file) as f:\n",
    "    mvr_json = json.load(f)\n",
    "\n",
    "mvr_sample = CVR.from_dict(mvr_json['ballots']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile entire sample\n",
    "cvr_sample_lookup, cvr_sample, mvr_phantoms_sample = sample_from_cvrs(cvr_list, manifest, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add MVRs for phantoms\n",
    "mvr_sample = mvr_sample + mvr_phantoms_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find measured risks for all assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_sample(mvr_sample, cvr_sample)\n",
    "p_max = find_p_values(contests, mvr_sample, cvr_sample, manifest_type, \\\n",
    "                      risk_function= risk_fn)\n",
    "print(\"maximum assertion p-value {}\".format(p_max))\n",
    "done = summarize_status(contests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the status of the audit \n",
    "write_audit_parameters(log_file, seed, replacement, risk_function, g, max_cards, len(cvr_list), \\\n",
    "                       manifest_cards, phantom_cards, error_rate, contests)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "state": {
    "6cab9cab294247839758fa9e8d64d122": {
     "views": [
      {
       "cell_index": 42
      }
     ]
    },
    "b7b0321f834d45ebb1bdc036fba7a916": {
     "views": [
      {
       "cell_index": 38
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
